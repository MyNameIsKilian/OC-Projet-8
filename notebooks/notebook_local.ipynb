{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "441159cc",
   "metadata": {},
   "source": [
    "# Déployez un modèle dans le cloud\n",
    "\n",
    "\n",
    "# Sommaire :\n",
    "\n",
    "**1. Préambule**<br />\n",
    "&emsp;1.1 Problématique<br />\n",
    "&emsp;1.2 Objectifs dans ce projet<br />\n",
    "&emsp;1.3 Déroulement des étapes du projet<br />\n",
    "**2. Choix techniques généraux retenus**<br />\n",
    "&emsp;2.1 Calcul distribué<br />\n",
    "&emsp;2.2 Transfert Learning<br />\n",
    "**3. Déploiement de la solution en local**<br />\n",
    "&emsp;3.1 Environnement de travail<br />\n",
    "&emsp;3.2 Installation de Spark<br />\n",
    "&emsp;3.3 Installation des packages<br />\n",
    "&emsp;3.4 Import des librairies<br />\n",
    "&emsp;3.5 Définition des PATH pour charger les images et enregistrer les résultats<br />\n",
    "&emsp;3.6 Création de la SparkSession<br />\n",
    "&emsp;3.7 Traitement des données<br />\n",
    "&emsp;&emsp;3.7.1 Chargement des données<br />\n",
    "&emsp;&emsp;3.7.2 Préparation du modèle<br />\n",
    "&emsp;&emsp;3.7.3 Définition du processus de chargement des images et application <br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;de leur featurisation à travers l'utilisation de pandas UDF<br />\n",
    "&emsp;&emsp;3.7.4 Exécution des actions d'extractions de features<br />\n",
    "&emsp;3.8 Chargement des données enregistrées et validation du résultat<br />\n",
    "**4. Déploiement de la solution sur le cloud**<br />\n",
    "&emsp;4.1 Choix du prestataire cloud : AWS<br />\n",
    "&emsp;4.2 Choix de la solution technique : EMR<br />\n",
    "&emsp;4.3 Choix de la solution de stockage des données : Amazon S3<br />\n",
    "&emsp;4.4 Configuration de l'environnement de travail<br />\n",
    "&emsp;4.5 Upload de nos données sur S3<br />\n",
    "&emsp;4.6 Configuration du serveur EMR<br />\n",
    "&emsp;&emsp;4.6.1 Étape 1 : Logiciels et étapes<br />\n",
    "&emsp;&emsp;&emsp;4.6.1.1 Configuration des logiciels<br />\n",
    "&emsp;&emsp;&emsp;4.6.1.2 Modifier les paramètres du logiciel<br />\n",
    "&emsp;&emsp;4.6.2 Étape 2 : Matériel<br />\n",
    "&emsp;&emsp;4.6.3 Étape 3 : Paramètres de cluster généraux<br />\n",
    "&emsp;&emsp;&emsp;4.6.3.1 Options générales<br />\n",
    "&emsp;&emsp;&emsp;4.6.3.2 Actions d'amorçage<br />\n",
    "&emsp;&emsp;4.6.4 Étape 4 : Sécurité<br />\n",
    "&emsp;&emsp;&emsp;4.6.4.1 Options de sécurité<br />\n",
    "&emsp;4.7 Instanciation du serveur<br />\n",
    "&emsp;4.8 Création du tunnel SSH à l'instance EC2 (Maître)<br />\n",
    "&emsp;&emsp;4.8.1 Création des autorisations sur les connexions entrantes<br />\n",
    "&emsp;&emsp;4.8.2 Création du tunnel ssh vers le Driver<br />\n",
    "&emsp;&emsp;4.8.3 Configuration de FoxyProxy<br />\n",
    "&emsp;&emsp;4.8.4 Accès aux applications du serveur EMR via le tunnel ssh<br />\n",
    "&emsp;4.9 Connexion au notebook JupyterHub<br />\n",
    "&emsp;4.10 Exécution du code<br />\n",
    "&emsp;&emsp;4.10.1 Démarrage de la session Spark<br />\n",
    "&emsp;&emsp;4.10.2 Installation des packages<br />\n",
    "&emsp;&emsp;4.10.3 Import des librairies<br />\n",
    "&emsp;&emsp;4.10.4 Définition des PATH pour charger les images et enregistrer les résultats<br />\n",
    "&emsp;&emsp;4.10.5 Traitement des données<br />\n",
    "&emsp;&emsp;&emsp;4.10.5.1 Chargement des données<br />\n",
    "&emsp;&emsp;&emsp;4.10.5.2 Préparation du modèle<br />\n",
    "&emsp;&emsp;&emsp;4.10.5.3 Définition du processus de chargement des images<br />\n",
    "&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;et application de leur featurisation à travers l'utilisation de pandas UDF<br />\n",
    "&emsp;&emsp;&emsp;4.10.5.4 Exécutions des actions d'extractions de features<br />\n",
    "&emsp;&emsp;4.10.6 Chargement des données enregistrées et validation du résultat<br />\n",
    "&emsp;4.11 Suivi de l'avancement des tâches avec le Serveur d'Historique Spark<br />\n",
    "&emsp;4.12 Résiliation de l'instance EMR<br />\n",
    "&emsp;4.13 Cloner le serveur EMR (si besoin)<br />\n",
    "&emsp;4.14 Arborescence du serveur S3 à la fin du projet<br />\n",
    "**5. Conclusion**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2cee08",
   "metadata": {},
   "source": [
    "# 1. Préambule\n",
    "\n",
    "## 1.1 Problématique\n",
    "\n",
    "La très jeune start-up de l'AgriTech, nommée \"**Fruits**!\", <br />\n",
    "cherche à proposer des solutions innovantes pour la récolte des fruits.\n",
    "\n",
    "La volonté de l’entreprise est de préserver la biodiversité des fruits <br />\n",
    "en permettant des traitements spécifiques pour chaque espèce de fruits <br />\n",
    "en développant des robots cueilleurs intelligents.\n",
    "\n",
    "La start-up souhaite dans un premier temps se faire connaître en mettant <br />\n",
    "à disposition du grand public une application mobile qui permettrait aux <br />\n",
    "utilisateurs de prendre en photo un fruit et d'obtenir des informations sur ce fruit.\n",
    "\n",
    "Pour la start-up, cette application permettrait de sensibiliser le grand public <br /> \n",
    "à la biodiversité des fruits et de mettre en place une première version du moteur <br />\n",
    "de classification des images de fruits.\n",
    "\n",
    "De plus, le développement de l’application mobile permettra de construire <br />\n",
    "une première version de l'architecture **Big Data** nécessaire.\n",
    "\n",
    "## 1.2 Objectifs dans ce projet\n",
    "\n",
    "1. Développer une première chaîne de traitement des données qui <br />\n",
    "   comprendra le **preprocessing** et une étape de **réduction de dimension**.\n",
    "2. Tenir compte du fait que <u>le volume de données va augmenter <br />\n",
    "   très rapidement</u> après la livraison de ce projet, ce qui implique de:\n",
    " - Déployer le traitement des données dans un environnement **Big Data**\n",
    " - Développer les scripts en **pyspark** pour effectuer du **calcul distribué**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b95e6ce",
   "metadata": {},
   "source": [
    "## 1.3 Déroulement des étapes du projet\n",
    "\n",
    "Le projet va être réalisé en 2 temps, dans deux environnements différents. <br />\n",
    "Nous allons dans un premier temps développer et exécuter notre code en local, <br />\n",
    "en travaillant sur un nombre limité d'images à traiter.\n",
    "\n",
    "Une fois les choix techniques validés, nous déploierons notre solution <br />\n",
    "dans un environnement Big Data en mode distribué.\n",
    "\n",
    "<u>Pour cette raison, ce projet sera divisé en 3 parties</u>:\n",
    "1. Liste des choix techniques généraux retenus\n",
    "2. Déploiement de la solution en local\n",
    "3. Déploiement de la solution dans le cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b34029",
   "metadata": {},
   "source": [
    "# 2. Choix techniques généraux retenus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32baf092",
   "metadata": {},
   "source": [
    "## 2.1 Calcul distribué\n",
    "\n",
    "L’énoncé du projet nous impose de développer des scripts en **pyspark** <br />\n",
    "afin de <u>prendre en compte l’augmentation très rapide du volume <br />\n",
    "de donné après la livraison du projet</u>.\n",
    "\n",
    "Pour comprendre rapidement et simplement ce qu’est **pyspark** <br />\n",
    "et son principe de fonctionnement, nous vous conseillons de lire <br />\n",
    "cet article : [PySpark : Tout savoir sur la librairie Python](https://datascientest.com/pyspark)\n",
    "\n",
    "<u>Le début de l’article nous dit ceci </u>:<br />\n",
    "« *Lorsque l’on parle de traitement de bases de données sur python, <br />\n",
    "on pense immédiatement à la librairie pandas. Cependant, lorsqu’on a <br />\n",
    "affaire à des bases de données trop massives, les calculs deviennent trop lents.<br />\n",
    "Heureusement, il existe une autre librairie python, assez proche <br />\n",
    "de pandas, qui permet de traiter des très grandes quantités de données : PySpark.<br />\n",
    "Apache Spark est un framework open-source développé par l’AMPLab <br />\n",
    "de UC Berkeley permettant de traiter des bases de données massives <br />\n",
    "en utilisant le calcul distribué, technique qui consiste à exploiter <br />\n",
    "plusieurs unités de calcul réparties en clusters au profit d’un seul <br />\n",
    "projet afin de diviser le temps d’exécution d’une requête.<br />\n",
    "Spark a été développé en Scala et est au meilleur de ses capacités <br />\n",
    "dans son langage natif. Cependant, la librairie PySpark propose de <br />\n",
    "l’utiliser avec le langage Python, en gardant des performances <br />\n",
    "similaires à des implémentations en Scala.<br />\n",
    "Pyspark est donc une bonne alternative à la librairie pandas lorsqu’on <br />\n",
    "cherche à traiter des jeux de données trop volumineux qui entraînent <br />\n",
    "des calculs trop chronophages.* »\n",
    "\n",
    "Comme nous le constatons, **pySpark** est un moyen de communiquer <br />\n",
    "avec **Spark** via le langage **Python**.<br />\n",
    "**Spark**, quant à lui, est un outil qui permet de gérer et de coordonner <br />\n",
    "l'exécution de tâches sur des données à travers un groupe d'ordinateurs. <br />\n",
    "<u>Spark (ou Apache Spark) est un framework open source de calcul distribué <br />\n",
    "in-memory pour le traitement et l'analyse de données massives</u>.\n",
    "\n",
    "Un autre [article très intéressant et beaucoup plus complet pour <br />\n",
    "comprendre le **fonctionnement de Spark**](https://www.veonum.com/apache-spark-pour-les-nuls/), ainsi que le rôle <br />\n",
    "des **Spark Session** que nous utiliserons dans ce projet.\n",
    "\n",
    "<u>Voici également un extrait</u>:\n",
    "\n",
    "*Les applications Spark se composent d’un pilote (« driver process ») <br />\n",
    "et de plusieurs exécuteurs (« executor processes »). Il peut être configuré <br />\n",
    "pour être lui-même l’exécuteur (local mode) ou en utiliser autant que <br />\n",
    "nécessaire pour traiter l’application, Spark prenant en charge la mise <br />\n",
    "à l’échelle automatique par une configuration d’un nombre minimum <br />\n",
    "et maximum d’exécuteurs.*\n",
    "\n",
    "![Schéma de Spark](img/spark-schema.png)\n",
    "\n",
    "*Le driver (parfois appelé « Spark Session ») distribue et planifie <br />\n",
    "les tâches entre les différents exécuteurs qui les exécutent et permettent <br />\n",
    "un traitement réparti. Il est le responsable de l’exécution du code <br />\n",
    "sur les différentes machines.\n",
    "\n",
    "Chaque exécuteur est un processus Java Virtual Machine (JVM) distinct <br />\n",
    "dont il est possible de configurer le nombre de CPU et la quantité de <br />\n",
    "mémoire qui lui est alloué. <br />\n",
    "Une seule tâche peut traiter un fractionnement de données à la fois.*\n",
    "\n",
    "Dans les deux environnements (Local et Cloud) nous utiliserons donc **Spark** <br />\n",
    "et nous l’exploiterons à travers des scripts python grâce à **PySpark**.\n",
    "\n",
    "Dans la <u>version locale</u> de notre script nous **simulerons <br />\n",
    "le calcul distribué** afin de valider que notre solution fonctionne.<br />\n",
    "Dans la <u>version cloud</u> nous **réaliserons les opérations sur un cluster de machine**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5364c9f9",
   "metadata": {},
   "source": [
    "## 2.2 Transfert Learning\n",
    "\n",
    "L'énoncé du projet nous demande également de <br />\n",
    "réaliser une première chaîne de traitement <br />\n",
    "des données qui comprendra le preprocessing et <br />\n",
    "une étape de réduction de dimension.\n",
    "\n",
    "Il est également précisé qu'il n'est pas nécessaire <br />\n",
    "d'entraîner un modèle pour le moment.\n",
    "\n",
    "Nous décidons de partir sur une solution de **transfert learning**.\n",
    "\n",
    "Simplement, le **transfert learning** consiste <br />\n",
    "à utiliser la connaissance déjà acquise <br />\n",
    "par un modèle entraîné (ici **MobileNetV2**) pour <br />\n",
    "l'adapter à notre problématique.\n",
    "\n",
    "Nous allons fournir au modèle nos images, et nous allons <br />\n",
    "<u>récupérer l'avant dernière couche</u> du modèle.<br />\n",
    "En effet la dernière couche de modèle est une couche softmax <br />\n",
    "qui permet la classification des images ce que nous ne <br />\n",
    "souhaitons pas dans ce projet.\n",
    "\n",
    "L'avant dernière couche correspond à un **vecteur <br />\n",
    "réduit** de dimension (1,1,1280).\n",
    "\n",
    "Cela permettra de réaliser une première version du moteur <br />\n",
    "pour la classification des images des fruits.\n",
    "\n",
    "**MobileNetV2** a été retenu pour sa <u>rapidité d'exécution</u>, <br />\n",
    "particulièrement adaptée pour le traitement d'un gros volume <br />\n",
    "de données ainsi que la <u>faible dimensionnalité du vecteur <br />\n",
    "de caractéristique en sortie</u> (1,1,1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e89a2da",
   "metadata": {},
   "source": [
    "# 3. Déploiement de la solution en local\n",
    "\n",
    "\n",
    "## 3.1 Environnement de travail\n",
    "\n",
    "Pour des raisons de simplicité, nous développons dans un environnement <br />\n",
    "Linux Unbuntu (exécuté depuis une machine Windows dans une machine virtuelle)\n",
    "* Pour installer une machine virtuelle :  https://www.malekal.com/meilleurs-logiciels-de-machine-virtuelle-gratuits-ou-payants/\n",
    "\n",
    "## 3.2 Installation de Spark\n",
    "\n",
    "[La première étape consiste à installer Spark ](https://computingforgeeks.com/how-to-install-apache-spark-on-ubuntu-debian/)\n",
    "\n",
    "## 3.3 Installation des packages\n",
    "\n",
    "<u>On installe ensuite à l'aide de la commande **pip** <br />\n",
    "les packages qui nous seront nécessaires</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "728d9256",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pandas in /home/kilian/anaconda3/lib/python3.9/site-packages (1.5.3)\n",
      "Requirement already satisfied: pillow in /home/kilian/anaconda3/lib/python3.9/site-packages (9.4.0)\n",
      "Requirement already satisfied: tensorflow in /home/kilian/anaconda3/lib/python3.9/site-packages (2.11.0)\n",
      "Requirement already satisfied: pyspark in /home/kilian/anaconda3/lib/python3.9/site-packages (3.4.1)\n",
      "Requirement already satisfied: pyarrow in /home/kilian/anaconda3/lib/python3.9/site-packages (11.0.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from Pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from Pandas) (2022.7)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/kilian/anaconda3/lib/python3.9/site-packages (from Pandas) (1.22.4)\n",
      "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.12,>=2.11 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.11.2)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.47.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (4.5.0)\n",
      "Requirement already satisfied: setuptools in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (66.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (3.19.4)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (14.0.6)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.4.0)\n",
      "Requirement already satisfied: keras<2.12,>=2.11.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (2.11.0)\n",
      "Requirement already satisfied: packaging in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorflow) (23.1.21)\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /home/kilian/anaconda3/lib/python3.9/site-packages (from pyspark) (0.10.9.7)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.11.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/kilian/anaconda3/lib/python3.9/site-packages (from tensorboard<2.12,>=2.11->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (5.2.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kilian/anaconda3/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/kilian/anaconda3/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (6.0.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/kilian/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/kilian/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/kilian/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/kilian/anaconda3/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard<2.12,>=2.11->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/kilian/anaconda3/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow) (3.11.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/kilian/anaconda3/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/kilian/anaconda3/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install Pandas pillow tensorflow pyspark pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a43845",
   "metadata": {},
   "source": [
    "## 3.4 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5c0c74f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 11:53:50.331839: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-12 11:53:55.251833: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-12 11:53:55.251852: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-12 11:54:03.299006: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-12 11:54:03.299450: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-12 11:54:03.299483: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "661ff67c",
   "metadata": {},
   "source": [
    "## 3.5 Définition des PATH pour charger les images <br /> et enregistrer les résultats\n",
    "\n",
    "Dans cette version locale nous partons du principe que les données <br />\n",
    "sont stockées dans le même répertoire que le notebook.<br />\n",
    "Nous n'utilisons qu'un extrait de **64 images** à traiter dans cette <br />\n",
    "première version en local.<br />\n",
    "L'extrait des images à charger est stockée dans le dossier **Test1**.<br />\n",
    "Nous enregistrerons le résultat de notre traitement <br />\n",
    "dans le dossier \"**Results_Local**\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cde0aa67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:        /home/kilian/workspaces/workspace-data/OC-P8-Fruits\n",
      "PATH_Data:   /home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Test1\n",
      "PATH_Result: /home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Results_Local\n"
     ]
    }
   ],
   "source": [
    "PATH = os.getcwd()\n",
    "PATH_Data = PATH+'/data/Test1'\n",
    "PATH_Result = PATH+'/data/Results_Local'\n",
    "print('PATH:        '+\\\n",
    "      PATH+'\\nPATH_Data:   '+\\\n",
    "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5e637a",
   "metadata": {},
   "source": [
    "## 3.6 Création de la SparkSession\n",
    "\n",
    "L’application Spark est contrôlée grâce à un processus de pilotage (driver process) appelé **SparkSession**. <br />\n",
    "<u>Une instance de **SparkSession** est la façon dont Spark exécute les fonctions définies par l’utilisateur <br />\n",
    "dans l’ensemble du cluster</u>. <u>Une SparkSession correspond toujours à une application Spark</u>.\n",
    "\n",
    "<u>Ici nous créons une session spark en spécifiant dans l'ordre</u> :\n",
    " 1. un **nom pour l'application**, qui sera affichée dans l'interface utilisateur Web Spark \"**P8**\"\n",
    " 2. que l'application doit s'exécuter **localement**. <br />\n",
    "   Nous ne définissons pas le nombre de cœurs à utiliser (comme .master('local[4]) pour 4 cœurs à utiliser), <br />\n",
    "   nous utiliserons donc tous les cœurs disponibles dans notre processeur.<br />\n",
    " 3. une option de configuration supplémentaire permettant d'utiliser le **format \"parquet\"** <br />\n",
    "   que nous utiliserons pour enregistrer et charger le résultat de notre travail.\n",
    " 4. vouloir **obtenir une session spark** existante ou si aucune n'existe, en créer une nouvelle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7bea157",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/12 11:55:03 WARN Utils: Your hostname, kilian-NP50DE-DB resolves to a loopback address: 127.0.1.1; using 192.168.1.40 instead (on interface wlp7s0)\n",
      "23/08/12 11:55:03 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/08/12 11:55:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession\n",
    "             .builder\n",
    "             .appName('P8')\n",
    "             .master('local')\n",
    "             .config(\"spark.sql.parquet.writeLegacyFormat\", 'true')\n",
    "             .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c8b53ac",
   "metadata": {},
   "source": [
    "<u>Nous créons également la variable \"**sc**\" qui est un **SparkContext** issue de la variable **spark**</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14aeccb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a086010",
   "metadata": {},
   "source": [
    "<u>Affichage des informations de Spark en cours d'execution</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e97bf13b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.40:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>P8</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc7872f96a0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195a88b0",
   "metadata": {},
   "source": [
    "## 3.7 Traitement des données\n",
    "\n",
    "<u>Dans la suite de notre flux de travail, <br />\n",
    "nous allons successivement</u> :\n",
    "1. Préparer nos données\n",
    "    1. Importer les images dans un dataframe **pandas UDF**\n",
    "    2. Associer aux images leur **label**\n",
    "    3. Préprocesser en **redimensionnant nos images pour <br />\n",
    "       qu'elles soient compatibles avec notre modèle**\n",
    "2. Préparer notre modèle\n",
    "    1. Importer le modèle **MobileNetV2**\n",
    "    2. Créer un **nouveau modèle** dépourvu de la dernière couche de MobileNetV2\n",
    "3. Définir le processus de chargement des images et l'application <br />\n",
    "   de leur featurisation à travers l'utilisation de pandas UDF\n",
    "4. Exécuter les actions d'extraction de features\n",
    "    1. Réduction de dimension avec une ACP\n",
    "5. Enregistrer le résultat de nos actions\n",
    "6. Tester le bon fonctionnement en chargeant les données enregistrées\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386fe0bc",
   "metadata": {},
   "source": [
    "### 3.7.1 Chargement des données\n",
    "\n",
    "Les images sont chargées au format binaire, ce qui offre, <br />\n",
    "plus de souplesse dans la façon de prétraiter les images.\n",
    "\n",
    "Avant de charger les images, nous spécifions que nous voulons charger <br />\n",
    "uniquement les fichiers dont l'extension est **jpg**.\n",
    "\n",
    "Nous indiquons également de charger tous les objets possibles contenus <br />\n",
    "dans les sous-dossiers du dossier communiqué."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "e68e53b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = spark.read.format(\"binaryFile\") \\\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "  .option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .load(PATH_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "0c447e94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+\n",
      "|                path|   modificationTime|length|             content|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "|file:/home/kilian...|2021-09-12 20:26:06|  5735|[FF D8 FF E0 00 1...|\n",
      "|file:/home/kilian...|2021-09-12 20:26:06|  5729|[FF D8 FF E0 00 1...|\n",
      "|file:/home/kilian...|2021-09-12 20:26:06|  5720|[FF D8 FF E0 00 1...|\n",
      "|file:/home/kilian...|2021-09-12 20:26:06|  5715|[FF D8 FF E0 00 1...|\n",
      "|file:/home/kilian...|2021-09-12 20:26:06|  5678|[FF D8 FF E0 00 1...|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645faeaf",
   "metadata": {},
   "source": [
    "<u>Affichage des 5 premières images contenant</u> :\n",
    " - le path de l'image\n",
    " - la date et heure de sa dernière modification\n",
    " - sa longueur\n",
    " - son contenu encodé en valeur hexadécimal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863981e5",
   "metadata": {},
   "source": [
    "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n",
    "    une colonne contenant les **labels** de chaque image</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a08b0494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "None\n",
      "+------------------------------------------------------------------------------------------+----------+\n",
      "|path                                                                                      |label     |\n",
      "+------------------------------------------------------------------------------------------+----------+\n",
      "|file:/home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Test1/Clementine/r_3_100.jpg|Clementine|\n",
      "|file:/home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Test1/Clementine/r_5_100.jpg|Clementine|\n",
      "|file:/home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Test1/Clementine/r_0_100.jpg|Clementine|\n",
      "|file:/home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Test1/Clementine/r_2_100.jpg|Clementine|\n",
      "|file:/home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Test1/Clementine/r_1_100.jpg|Clementine|\n",
      "+------------------------------------------------------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0cbf23b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# j'ai bien 16 images x 4 catégories dans mon dossier Test1\n",
    "images.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d47705",
   "metadata": {},
   "source": [
    "### 3.7.2 Préparation du modèle\n",
    "\n",
    "Je vais utiliser la technique du **transfert learning** pour extraire les features des images.<br />\n",
    "J'ai choisi d'utiliser le modèle **MobileNetV2** pour sa rapidité d'exécution comparée <br />\n",
    "à d'autres modèles comme *VGG16* par exemple.\n",
    "\n",
    "Pour en savoir plus sur la conception et le fonctionnement de MobileNetV2, <br />\n",
    "je vous invite à lire [cet article](https://towardsdatascience.com/review-mobilenetv2-light-weight-model-image-classification-8febb490e61c).\n",
    "\n",
    "<u>Voici le schéma de son architecture globale</u> : \n",
    "\n",
    "![Architecture de MobileNetV2](img/mobilenetv2_architecture.png)\n",
    "\n",
    "Il existe une dernière couche qui sert à classer les images <br />\n",
    "selon 1000 catégories que nous ne voulons pas utiliser.<br />\n",
    "L'idée dans ce projet est de récupérer le **vecteur de caractéristiques <br />\n",
    "de dimensions (1,1,1280)** qui servira, plus tard, au travers d'un moteur <br />\n",
    "de classification à reconnaitre les différents fruits du jeu de données.\n",
    "\n",
    "Comme d'autres modèles similaires, **MobileNetV2**, lorsqu'on l'utilise <br />\n",
    "en incluant toutes ses couches, attend obligatoirement des images <br />\n",
    "de dimension (224,224,3). Nos images étant toutes de dimension (100,100,3), <br />\n",
    "nous devrons simplement les **redimensionner** avant de les confier au modèle.\n",
    "\n",
    "<u>Dans l'odre</u> :\n",
    " 1. Nous chargeons le modèle **MobileNetV2** avec les poids **précalculés** <br />\n",
    "    issus d'**imagenet** et en spécifiant le format de nos images en entrée\n",
    " 2. Nous créons un nouveau modèle avec:\n",
    "  - <u>en entrée</u> : l'entrée du modèle MobileNetV2\n",
    "  - <u>en sortie</u> : l'avant dernière couche du modèle MobileNetV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9cdd9bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-12 11:59:28.822619: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-12 11:59:28.822692: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-12 11:59:28.822744: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kilian-NP50DE-DB): /proc/driver/nvidia/version does not exist\n",
      "2023-08-12 11:59:28.871406: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                    include_top=True,\n",
    "                    input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d6b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b197379",
   "metadata": {},
   "source": [
    "Affichage du résumé de notre nouveau modèle où nous constatons <br />\n",
    "que <u>nous récupérons bien en sortie un vecteur de dimension (1, 1, 1280)</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0574f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 1280)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_model.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e8207725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " Conv1 (Conv2D)                 (None, 112, 112, 32  864         ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " bn_Conv1 (BatchNormalization)  (None, 112, 112, 32  128         ['Conv1[0][0]']                  \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " Conv1_relu (ReLU)              (None, 112, 112, 32  0           ['bn_Conv1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise (Depth  (None, 112, 112, 32  288        ['Conv1_relu[0][0]']             \n",
      " wiseConv2D)                    )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_BN (Ba  (None, 112, 112, 32  128        ['expanded_conv_depthwise[0][0]']\n",
      " tchNormalization)              )                                                                 \n",
      "                                                                                                  \n",
      " expanded_conv_depthwise_relu (  (None, 112, 112, 32  0          ['expanded_conv_depthwise_BN[0][0\n",
      " ReLU)                          )                                ]']                              \n",
      "                                                                                                  \n",
      " expanded_conv_project (Conv2D)  (None, 112, 112, 16  512        ['expanded_conv_depthwise_relu[0]\n",
      "                                )                                [0]']                            \n",
      "                                                                                                  \n",
      " expanded_conv_project_BN (Batc  (None, 112, 112, 16  64         ['expanded_conv_project[0][0]']  \n",
      " hNormalization)                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand (Conv2D)        (None, 112, 112, 96  1536        ['expanded_conv_project_BN[0][0]'\n",
      "                                )                                ]                                \n",
      "                                                                                                  \n",
      " block_1_expand_BN (BatchNormal  (None, 112, 112, 96  384        ['block_1_expand[0][0]']         \n",
      " ization)                       )                                                                 \n",
      "                                                                                                  \n",
      " block_1_expand_relu (ReLU)     (None, 112, 112, 96  0           ['block_1_expand_BN[0][0]']      \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_pad (ZeroPadding2D)    (None, 113, 113, 96  0           ['block_1_expand_relu[0][0]']    \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " block_1_depthwise (DepthwiseCo  (None, 56, 56, 96)  864         ['block_1_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_1_depthwise_BN (BatchNor  (None, 56, 56, 96)  384         ['block_1_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_1_depthwise_relu (ReLU)  (None, 56, 56, 96)   0           ['block_1_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_1_project (Conv2D)       (None, 56, 56, 24)   2304        ['block_1_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_1_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_1_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_1_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_2_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_2_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_2_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_2_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_2_depthwise (DepthwiseCo  (None, 56, 56, 144)  1296       ['block_2_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_2_depthwise_BN (BatchNor  (None, 56, 56, 144)  576        ['block_2_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_2_depthwise_relu (ReLU)  (None, 56, 56, 144)  0           ['block_2_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_2_project (Conv2D)       (None, 56, 56, 24)   3456        ['block_2_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_2_project_BN (BatchNorma  (None, 56, 56, 24)  96          ['block_2_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_2_add (Add)              (None, 56, 56, 24)   0           ['block_1_project_BN[0][0]',     \n",
      "                                                                  'block_2_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_3_expand (Conv2D)        (None, 56, 56, 144)  3456        ['block_2_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_3_expand_BN (BatchNormal  (None, 56, 56, 144)  576        ['block_3_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_3_expand_relu (ReLU)     (None, 56, 56, 144)  0           ['block_3_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_3_pad (ZeroPadding2D)    (None, 57, 57, 144)  0           ['block_3_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_3_depthwise (DepthwiseCo  (None, 28, 28, 144)  1296       ['block_3_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_3_depthwise_BN (BatchNor  (None, 28, 28, 144)  576        ['block_3_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_3_depthwise_relu (ReLU)  (None, 28, 28, 144)  0           ['block_3_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_3_project (Conv2D)       (None, 28, 28, 32)   4608        ['block_3_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_3_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_3_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_3_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_4_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_4_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_4_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_4_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_4_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_4_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_4_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_4_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_4_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_4_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_4_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_4_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_4_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_4_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_4_add (Add)              (None, 28, 28, 32)   0           ['block_3_project_BN[0][0]',     \n",
      "                                                                  'block_4_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_5_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_4_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_5_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_5_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_5_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_5_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_5_depthwise (DepthwiseCo  (None, 28, 28, 192)  1728       ['block_5_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_5_depthwise_BN (BatchNor  (None, 28, 28, 192)  768        ['block_5_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_5_depthwise_relu (ReLU)  (None, 28, 28, 192)  0           ['block_5_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_5_project (Conv2D)       (None, 28, 28, 32)   6144        ['block_5_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_5_project_BN (BatchNorma  (None, 28, 28, 32)  128         ['block_5_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_5_add (Add)              (None, 28, 28, 32)   0           ['block_4_add[0][0]',            \n",
      "                                                                  'block_5_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_6_expand (Conv2D)        (None, 28, 28, 192)  6144        ['block_5_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_6_expand_BN (BatchNormal  (None, 28, 28, 192)  768        ['block_6_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_6_expand_relu (ReLU)     (None, 28, 28, 192)  0           ['block_6_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_6_pad (ZeroPadding2D)    (None, 29, 29, 192)  0           ['block_6_expand_relu[0][0]']    \n",
      "                                                                                                  \n",
      " block_6_depthwise (DepthwiseCo  (None, 14, 14, 192)  1728       ['block_6_pad[0][0]']            \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_6_depthwise_BN (BatchNor  (None, 14, 14, 192)  768        ['block_6_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_6_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           ['block_6_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_6_project (Conv2D)       (None, 14, 14, 64)   12288       ['block_6_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_6_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_6_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_6_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_7_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_7_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_7_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_7_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_7_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_7_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_7_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_7_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_7_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_7_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_7_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_7_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_7_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_7_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_7_add (Add)              (None, 14, 14, 64)   0           ['block_6_project_BN[0][0]',     \n",
      "                                                                  'block_7_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_8_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_7_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_8_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_8_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_8_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_8_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_8_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_8_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_8_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_8_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_8_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_8_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_8_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_8_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_8_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_8_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_8_add (Add)              (None, 14, 14, 64)   0           ['block_7_add[0][0]',            \n",
      "                                                                  'block_8_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_9_expand (Conv2D)        (None, 14, 14, 384)  24576       ['block_8_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_9_expand_BN (BatchNormal  (None, 14, 14, 384)  1536       ['block_9_expand[0][0]']         \n",
      " ization)                                                                                         \n",
      "                                                                                                  \n",
      " block_9_expand_relu (ReLU)     (None, 14, 14, 384)  0           ['block_9_expand_BN[0][0]']      \n",
      "                                                                                                  \n",
      " block_9_depthwise (DepthwiseCo  (None, 14, 14, 384)  3456       ['block_9_expand_relu[0][0]']    \n",
      " nv2D)                                                                                            \n",
      "                                                                                                  \n",
      " block_9_depthwise_BN (BatchNor  (None, 14, 14, 384)  1536       ['block_9_depthwise[0][0]']      \n",
      " malization)                                                                                      \n",
      "                                                                                                  \n",
      " block_9_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           ['block_9_depthwise_BN[0][0]']   \n",
      "                                                                                                  \n",
      " block_9_project (Conv2D)       (None, 14, 14, 64)   24576       ['block_9_depthwise_relu[0][0]'] \n",
      "                                                                                                  \n",
      " block_9_project_BN (BatchNorma  (None, 14, 14, 64)  256         ['block_9_project[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_9_add (Add)              (None, 14, 14, 64)   0           ['block_8_add[0][0]',            \n",
      "                                                                  'block_9_project_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_expand (Conv2D)       (None, 14, 14, 384)  24576       ['block_9_add[0][0]']            \n",
      "                                                                                                  \n",
      " block_10_expand_BN (BatchNorma  (None, 14, 14, 384)  1536       ['block_10_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_10_expand_relu (ReLU)    (None, 14, 14, 384)  0           ['block_10_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_10_depthwise (DepthwiseC  (None, 14, 14, 384)  3456       ['block_10_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_10_depthwise_BN (BatchNo  (None, 14, 14, 384)  1536       ['block_10_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0          ['block_10_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_10_project (Conv2D)      (None, 14, 14, 96)   36864       ['block_10_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_10_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_10_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_10_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_11_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_11_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_11_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_11_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_11_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_11_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_11_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_11_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_11_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_11_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_11_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_11_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_11_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_11_add (Add)             (None, 14, 14, 96)   0           ['block_10_project_BN[0][0]',    \n",
      "                                                                  'block_11_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_12_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_11_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_12_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_12_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_12_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_12_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_12_depthwise (DepthwiseC  (None, 14, 14, 576)  5184       ['block_12_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_12_depthwise_BN (BatchNo  (None, 14, 14, 576)  2304       ['block_12_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0          ['block_12_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_12_project (Conv2D)      (None, 14, 14, 96)   55296       ['block_12_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_12_project_BN (BatchNorm  (None, 14, 14, 96)  384         ['block_12_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_12_add (Add)             (None, 14, 14, 96)   0           ['block_11_add[0][0]',           \n",
      "                                                                  'block_12_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_13_expand (Conv2D)       (None, 14, 14, 576)  55296       ['block_12_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_13_expand_BN (BatchNorma  (None, 14, 14, 576)  2304       ['block_13_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_13_expand_relu (ReLU)    (None, 14, 14, 576)  0           ['block_13_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_13_pad (ZeroPadding2D)   (None, 15, 15, 576)  0           ['block_13_expand_relu[0][0]']   \n",
      "                                                                                                  \n",
      " block_13_depthwise (DepthwiseC  (None, 7, 7, 576)   5184        ['block_13_pad[0][0]']           \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_13_depthwise_BN (BatchNo  (None, 7, 7, 576)   2304        ['block_13_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)   0           ['block_13_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_13_project (Conv2D)      (None, 7, 7, 160)    92160       ['block_13_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_13_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_13_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_13_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_14_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_14_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_14_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_14_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_14_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_14_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_14_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_14_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_14_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_14_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_14_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_14_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_14_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_14_add (Add)             (None, 7, 7, 160)    0           ['block_13_project_BN[0][0]',    \n",
      "                                                                  'block_14_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_15_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_14_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_15_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_15_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_15_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_15_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_15_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_15_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_15_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_15_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_15_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_15_project (Conv2D)      (None, 7, 7, 160)    153600      ['block_15_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_15_project_BN (BatchNorm  (None, 7, 7, 160)   640         ['block_15_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " block_15_add (Add)             (None, 7, 7, 160)    0           ['block_14_add[0][0]',           \n",
      "                                                                  'block_15_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " block_16_expand (Conv2D)       (None, 7, 7, 960)    153600      ['block_15_add[0][0]']           \n",
      "                                                                                                  \n",
      " block_16_expand_BN (BatchNorma  (None, 7, 7, 960)   3840        ['block_16_expand[0][0]']        \n",
      " lization)                                                                                        \n",
      "                                                                                                  \n",
      " block_16_expand_relu (ReLU)    (None, 7, 7, 960)    0           ['block_16_expand_BN[0][0]']     \n",
      "                                                                                                  \n",
      " block_16_depthwise (DepthwiseC  (None, 7, 7, 960)   8640        ['block_16_expand_relu[0][0]']   \n",
      " onv2D)                                                                                           \n",
      "                                                                                                  \n",
      " block_16_depthwise_BN (BatchNo  (None, 7, 7, 960)   3840        ['block_16_depthwise[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)   0           ['block_16_depthwise_BN[0][0]']  \n",
      "                                                                                                  \n",
      " block_16_project (Conv2D)      (None, 7, 7, 320)    307200      ['block_16_depthwise_relu[0][0]']\n",
      "                                                                                                  \n",
      " block_16_project_BN (BatchNorm  (None, 7, 7, 320)   1280        ['block_16_project[0][0]']       \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " Conv_1 (Conv2D)                (None, 7, 7, 1280)   409600      ['block_16_project_BN[0][0]']    \n",
      "                                                                                                  \n",
      " Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)  5120        ['Conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " out_relu (ReLU)                (None, 7, 7, 1280)   0           ['Conv_1_bn[0][0]']              \n",
      "                                                                                                  \n",
      " global_average_pooling2d (Glob  (None, 1280)        0           ['out_relu[0][0]']               \n",
      " alAveragePooling2D)                                                                              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0adcf5",
   "metadata": {},
   "source": [
    "Tous les workeurs doivent pouvoir accéder au modèle ainsi qu'à ses poids. <br />\n",
    "Une bonne pratique consiste à charger le modèle sur le driver puis à diffuser <br />\n",
    "ensuite les poids aux différents workeurs.<br />\n",
    "Cette étape correspond au traitement de diffusion des poids du modèle Tensorflow sur les clusters (broadcast des “weights” du modèle) demandé dans l'énoncé du projet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1cc53ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "brodcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc0e34e",
   "metadata": {},
   "source": [
    "<u>Mettons cela sous forme de fonction</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3fd51ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet',\n",
    "                        include_top=True,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5620876",
   "metadata": {},
   "source": [
    "### 3.7.3 Définition du processus de chargement des images et application <br/>de leur featurisation à travers l'utilisation de pandas UDF\n",
    "\n",
    "Ce notebook définit la logique par étapes, jusqu'à Pandas UDF.\n",
    "\n",
    "<u>L'empilement des appels est la suivante</u> :\n",
    "\n",
    "- Pandas UDF\n",
    "  - featuriser une série d'images pd.Series\n",
    "   - prétraiter une image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dc4e5f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kilian/anaconda3/lib/python3.9/site-packages/pyspark/sql/pandas/functions.py:399: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdf2ef9",
   "metadata": {},
   "source": [
    "### 3.7.4 Exécution des actions d'extraction de features\n",
    "\n",
    "Les Pandas UDF, sur de grands enregistrements (par exemple, de très grandes images), <br />\n",
    "peuvent rencontrer des erreurs de type Out Of Memory (OOM).<br />\n",
    "Si vous rencontrez de telles erreurs dans la cellule ci-dessous, <br />\n",
    "essayez de réduire la taille du lot Arrow via 'maxRecordsPerBatch'\n",
    "\n",
    "Je n'utiliserai pas cette commande dans ce projet <br />\n",
    "et je laisse donc la commande en commentaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f30d28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f8f95d",
   "metadata": {},
   "source": [
    "Nous pouvons maintenant exécuter la featurisation sur l'ensemble de notre DataFrame Spark.<br />\n",
    "<u>REMARQUE</u> : Cela peut prendre beaucoup de temps, tout dépend du volume de données à traiter. <br />\n",
    "\n",
    "Notre jeu de données de **Test** contenu dans le dossier **Test_S3** contient **22688 images**. <br />\n",
    "Cependant, dans l'exécution en mode **local**, <br />\n",
    "nous <u>traiterons un ensemble réduit de **64 images**</u>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fc2179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of files 22688\n",
      "Total Number of directories 131\n",
      "Total: 22819\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "APP_FOLDER = 'data/Test_S3'\n",
    "totalFiles = 0\n",
    "totalDir = 0\n",
    "\n",
    "for base, dirs, files in os.walk(APP_FOLDER):\n",
    "    for directories in dirs:\n",
    "        totalDir += 1\n",
    "    for Files in files:\n",
    "        totalFiles += 1\n",
    "\n",
    "print('Total number of files',totalFiles)\n",
    "print('Total Number of directories',totalDir)\n",
    "print('Total:',(totalDir + totalFiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "69c1767c",
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = images.repartition(20).select(col(\"path\"),\n",
    "                                            col(\"label\"),\n",
    "                                            featurize_udf(\"content\").alias(\"features\")\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ead23f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[path: string, label: string, features: array<float>]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "01bb1603",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 11:13:17.799666: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-13 11:13:17.904765: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-13 11:13:17.904782: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-13 11:13:18.474845: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-13 11:13:18.474904: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-13 11:13:18.474912: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-08-13 11:13:19.390186: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-13 11:13:19.390205: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-13 11:13:19.390228: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kilian-NP50DE-DB): /proc/driver/nvidia/version does not exist\n",
      "2023-08-13 11:13:19.390401: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 723ms/step\n",
      "1/1 [==============================] - 1s 514ms/step                (0 + 1) / 2]\n",
      "[Stage 15:=============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+\n",
      "|                path|     label|            features|\n",
      "+--------------------+----------+--------------------+\n",
      "|file:/home/kilian...|Clementine|[0.15727535, 0.0,...|\n",
      "|file:/home/kilian...|Strawberry|[1.3659481, 0.098...|\n",
      "|file:/home/kilian...|    Banana|[1.4225855, 0.082...|\n",
      "|file:/home/kilian...|Clementine|[0.5118644, 0.078...|\n",
      "|file:/home/kilian...|    Banana|[1.7645273, 0.001...|\n",
      "+--------------------+----------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 516ms/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "features_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5e83ec",
   "metadata": {},
   "source": [
    "<u>Rappel du PATH où seront inscrits les fichiers au format \"**parquet**\" <br />\n",
    "contenant nos résultats, à savoir, un DataFrame contenant 4 colonnes</u> :\n",
    " 1. Path des images\n",
    " 2. Label de l'image\n",
    " 3. Features extraites de l'image (1280)\n",
    " 4. Vecteur de caractéristiques de l'image réduit à l'aide d'une ACP (k composantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "67fcdb0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/kilian/workspaces/workspace-data/OC-P8-Fruits/data/Results_Local\n"
     ]
    }
   ],
   "source": [
    "print(PATH_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2775a6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from typing import Iterator\n",
    "from sklearn.decomposition import PCA as sklearn_PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pyspark.sql.functions import col, pandas_udf, element_at, split\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "from pyspark.ml.feature import PCA as spark_PCA, StandardScaler as spark_scaler\n",
    "from pyspark.ml.linalg import Vectors, VectorUDT, SparseVector, DenseVector\n",
    "from pyspark.sql.functions import udf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fb74e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 22:50:59.132824: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-13 22:50:59.230297: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-13 22:50:59.230313: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-13 22:50:59.779403: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-13 22:50:59.779461: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-13 22:50:59.779468: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-08-13 22:51:00.675936: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-13 22:51:00.675954: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-13 22:51:00.675968: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kilian-NP50DE-DB): /proc/driver/nvidia/version does not exist\n",
      "2023-08-13 22:51:00.676116: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 579ms/step\n",
      "1/1 [==============================] - 1s 512ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 536ms/step               (2 + 1) / 20]\n",
      "1/1 [==============================] - 1s 511ms/step               (3 + 1) / 20]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc3e4d58b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 517ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc30818ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 523ms/step\n",
      "1/1 [==============================] - 1s 526ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 546ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 619ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 531ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 539ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 534ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 514ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 522ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 538ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 525ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 523ms/step==>           (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 570ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 533ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 527ms/step===========>  (19 + 1) / 20]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Création d'un dataframe Pandas\n",
    "feature_df_pd = features_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "83427d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Clementine</td>\n",
       "      <td>[0.15727534890174866, 0.0, 0.0, 0.0, 0.0, 0.20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>[1.3659480810165405, 0.09833923727273941, 0.00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Banana</td>\n",
       "      <td>[1.4225854873657227, 0.08237817138433456, 0.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Clementine</td>\n",
       "      <td>[0.511864423751831, 0.07806168496608734, 0.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Banana</td>\n",
       "      <td>[1.7645273208618164, 0.0011792182922363281, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path       label  \\\n",
       "0  file:/home/kilian/workspaces/workspace-data/OC...  Clementine   \n",
       "1  file:/home/kilian/workspaces/workspace-data/OC...  Strawberry   \n",
       "2  file:/home/kilian/workspaces/workspace-data/OC...      Banana   \n",
       "3  file:/home/kilian/workspaces/workspace-data/OC...  Clementine   \n",
       "4  file:/home/kilian/workspaces/workspace-data/OC...      Banana   \n",
       "\n",
       "                                            features  \n",
       "0  [0.15727534890174866, 0.0, 0.0, 0.0, 0.0, 0.20...  \n",
       "1  [1.3659480810165405, 0.09833923727273941, 0.00...  \n",
       "2  [1.4225854873657227, 0.08237817138433456, 0.0,...  \n",
       "3  [0.511864423751831, 0.07806168496608734, 0.0, ...  \n",
       "4  [1.7645273208618164, 0.0011792182922363281, 0....  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_df_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "49388e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original features size : (64, 1280)\n",
      "reduced features size : (64, 26)\n"
     ]
    }
   ],
   "source": [
    "# On scale nos features puis on applique un ACP pour réduire leur dimension\n",
    "features_array = np.array(feature_df_pd['features'].tolist())\n",
    "print(\"original features size :\", features_array.shape)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_features = scaler.fit_transform(features_array)\n",
    "\n",
    "explained_variance = 0.90\n",
    "pca = sklearn_PCA(n_components=explained_variance)\n",
    "features_pca = pca.fit_transform(scaled_features)\n",
    "print(\"reduced features size :\", features_pca.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a87c50d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc64473f6d0>]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# On passe donc de 1280 features à 26 features (qui expliquent 90% de la variance)\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(pca.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "c2f9020a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Création de notre dataframe Spark final - conversion des arrays en vecteurs\n",
    "list_to_vector_udf = udf(lambda l: Vectors.dense(l), VectorUDT())\n",
    "\n",
    "df_spark_vector = features_df.select(\n",
    "    features_df[\"path\"],\n",
    "    features_df[\"label\"], \n",
    "    list_to_vector_udf(features_df[\"features\"]).alias(\"features\")\n",
    ")\n",
    "\n",
    "df_spark_vector.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b674ce4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-13 23:54:50.705971: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-13 23:54:50.805821: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-13 23:54:50.805839: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-13 23:54:51.408903: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-13 23:54:51.408959: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-13 23:54:51.408966: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-08-13 23:54:52.347681: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-13 23:54:52.347698: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-13 23:54:52.347713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kilian-NP50DE-DB): /proc/driver/nvidia/version does not exist\n",
      "2023-08-13 23:54:52.347867: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 600ms/step\n",
      "1/1 [==============================] - 1s 526ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 533ms/step               (2 + 1) / 20]\n",
      "1/1 [==============================] - 1s 544ms/step               (3 + 1) / 20]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc3e4d58b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 546ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc30818ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 525ms/step\n",
      "1/1 [==============================] - 1s 526ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 537ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 571ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 535ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 554ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 537ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 578ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 548ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 550ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 532ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 536ms/step==>           (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 541ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 525ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 537ms/step===========>  (19 + 1) / 20]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# StandardScaler de la librairie Spark\n",
    "scaler = spark_scaler(\n",
    "    inputCol = 'features', \n",
    "    outputCol = 'scaled_features',\n",
    "    withMean = True,\n",
    "    withStd = True\n",
    ").fit(df_spark_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "d39ee1a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 549ms/step                (0 + 1) / 1]\n",
      "1/1 [==============================] - 1s 533ms/step                (0 + 1) / 2]\n",
      "[Stage 107:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+\n",
      "|                path|     label|            features|     scaled_features|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "|file:/home/kilian...|Clementine|[0.15727534890174...|[-1.2595558414230...|\n",
      "|file:/home/kilian...|Strawberry|[1.36594808101654...|[1.05345249320842...|\n",
      "|file:/home/kilian...|    Banana|[1.42258548736572...|[1.16183815415434...|\n",
      "|file:/home/kilian...|Clementine|[0.51186442375183...|[-0.5809871406445...|\n",
      "|file:/home/kilian...|    Banana|[1.76452732086181...|[1.81620412917869...|\n",
      "|file:/home/kilian...|Strawberry|[0.77831923961639...|[-0.0710788805160...|\n",
      "+--------------------+----------+--------------------+--------------------+\n",
      "only showing top 6 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 551ms/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark_vector = scaler.transform(df_spark_vector)\n",
    "df_spark_vector.show(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "e832bb14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA_a86f69573413"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ACP de la librairie Spark\n",
    "spark_pca = spark_PCA(k=features_pca.shape[1], inputCol=\"scaled_features\")\n",
    "spark_pca.setOutputCol(\"pca_features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "69ee7e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 00:02:21.785099: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 00:02:21.886019: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-14 00:02:21.886036: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-14 00:02:22.441003: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-14 00:02:22.441067: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-14 00:02:22.441075: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-08-14 00:02:23.368753: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-14 00:02:23.368770: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-14 00:02:23.368785: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kilian-NP50DE-DB): /proc/driver/nvidia/version does not exist\n",
      "2023-08-14 00:02:23.368935: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 1s 618ms/step\n",
      "1/1 [==============================] - 1s 518ms/step                (0 + 1) / 1]\n",
      "1/1 [==============================] - 1s 538ms/step               (0 + 1) / 20]\n",
      "1/1 [==============================] - 1s 537ms/step               (1 + 1) / 20]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc3e4d48b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 553ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc30816ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 551ms/step\n",
      "1/1 [==============================] - 1s 531ms/step               (4 + 1) / 20]\n",
      "1/1 [==============================] - 1s 534ms/step               (5 + 1) / 20]\n",
      "1/1 [==============================] - 1s 550ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 553ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 548ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 535ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 534ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 547ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 538ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 548ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 565ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 553ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 534ms/step===>          (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 519ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 536ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 553ms/step===========>  (19 + 1) / 20]\n",
      "1/1 [==============================] - 1s 523ms/step                (0 + 1) / 1]\n",
      "1/1 [==============================] - 1s 540ms/step               (0 + 1) / 20]\n",
      "1/1 [==============================] - 1s 526ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 535ms/step               (2 + 1) / 20]\n",
      "1/1 [==============================] - 1s 540ms/step               (3 + 1) / 20]\n",
      "1/1 [==============================] - 1s 554ms/step               (4 + 1) / 20]\n",
      "1/1 [==============================] - 1s 558ms/step               (5 + 1) / 20]\n",
      "1/1 [==============================] - 1s 568ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 554ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 590ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 529ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 526ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 542ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 537ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 544ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 544ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 568ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 517ms/step===>          (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 526ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 520ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 528ms/step===========>  (19 + 1) / 20]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark_pca_model = spark_pca.fit(df_spark_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "9c00037c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26\n"
     ]
    }
   ],
   "source": [
    "# On reste à 26 composantes comme lors de l'ACP avec sklearn\n",
    "print(spark_pca_model.getK())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "80989891",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark_vector = spark_pca_model.transform(dataset=df_spark_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "dead8ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 526ms/step                (0 + 1) / 1]\n",
      "1/1 [==============================] - 1s 526ms/step                (0 + 1) / 2]\n",
      "[Stage 125:============================>                            (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|                path|     label|            features|     scaled_features|        pca_features|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "|file:/home/kilian...|Clementine|[0.15727534890174...|[-1.2595558414230...|[5.24053856546943...|\n",
      "|file:/home/kilian...|Strawberry|[1.36594808101654...|[1.05345249320842...|[7.60194355094782...|\n",
      "|file:/home/kilian...|    Banana|[1.42258548736572...|[1.16183815415434...|[-25.419240298328...|\n",
      "|file:/home/kilian...|Clementine|[0.51186442375183...|[-0.5809871406445...|[7.44430266889824...|\n",
      "|file:/home/kilian...|    Banana|[1.76452732086181...|[1.81620412917869...|[-25.570767635673...|\n",
      "+--------------------+----------+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 562ms/step\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_spark_vector.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "6c24c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_to_array_udf = udf(\n",
    "    lambda vector: vector.toArray().tolist()\n",
    "    if isinstance(vector, (DenseVector, SparseVector))\n",
    "    else vector,\n",
    "    ArrayType(FloatType())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "d70ccfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# On doit repasser les vecteurs en array pour qu'ils soient lisibles en Python\n",
    "df_spark_vector = df_spark_vector.withColumn(\"features\", vector_to_array_udf(df_spark_vector[\"features\"]))\n",
    "df_spark_vector = df_spark_vector.withColumn(\"pca_features\", vector_to_array_udf(df_spark_vector[\"pca_features\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "1c0f87d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      " |-- pca_features: array (nullable = true)\n",
      " |    |-- element: float (containsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spark_results = df_spark_vector.select(\n",
    "    df_spark_vector[\"path\"],\n",
    "    df_spark_vector[\"label\"], \n",
    "    # df_spark_vector[\"features\"],\n",
    "    df_spark_vector[\"pca_features\"]\n",
    ")\n",
    "\n",
    "df_spark_results.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4aee269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8901db3",
   "metadata": {},
   "source": [
    "<u>Enregistrement des données traitées au format \"**parquet**\"</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ea598e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-14 15:08:56.230754: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-14 15:08:56.333384: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-08-14 15:08:56.333401: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-08-14 15:08:56.887379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-14 15:08:56.919012: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-08-14 15:08:56.919046: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2023-08-14 15:09:00.715881: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2023-08-14 15:09:00.715899: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-08-14 15:09:00.715913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (kilian-NP50DE-DB): /proc/driver/nvidia/version does not exist\n",
      "2023-08-14 15:09:00.716080: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "1/1 [==============================] - 3s 3s/step\n",
      "1/1 [==============================] - 1s 516ms/step               (1 + 1) / 20]\n",
      "1/1 [==============================] - 1s 504ms/step               (2 + 1) / 20]\n",
      "1/1 [==============================] - 1s 507ms/step               (3 + 1) / 20]\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc3e4d58b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fdc30818ee0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 522ms/step\n",
      "1/1 [==============================] - 1s 517ms/step               (6 + 1) / 20]\n",
      "1/1 [==============================] - 1s 525ms/step               (7 + 1) / 20]\n",
      "1/1 [==============================] - 1s 528ms/step               (8 + 1) / 20]\n",
      "1/1 [==============================] - 1s 531ms/step               (9 + 1) / 20]\n",
      "1/1 [==============================] - 1s 515ms/step              (10 + 1) / 20]\n",
      "1/1 [==============================] - 1s 539ms/step              (11 + 1) / 20]\n",
      "1/1 [==============================] - 1s 533ms/step              (12 + 1) / 20]\n",
      "1/1 [==============================] - 1s 580ms/step              (13 + 1) / 20]\n",
      "1/1 [==============================] - 1s 539ms/step              (14 + 1) / 20]\n",
      "1/1 [==============================] - 1s 521ms/step>             (15 + 1) / 20]\n",
      "1/1 [==============================] - 1s 526ms/step===>          (16 + 1) / 20]\n",
      "1/1 [==============================] - 1s 510ms/step=====>        (17 + 1) / 20]\n",
      "1/1 [==============================] - 1s 527ms/step========>     (18 + 1) / 20]\n",
      "1/1 [==============================] - 1s 522ms/step===========>  (19 + 1) / 20]\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Une fois l'ACP réalisée, enregistrer les résultats dans le path result sous forme de parquet\n",
    "df_spark_results.write.mode(\"overwrite\").parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9506f21",
   "metadata": {},
   "source": [
    "## 3.8 Chargement des données enregistrées et validation du résultat\n",
    "\n",
    "<u>On charge les données fraichement enregistrées dans un **DataFrame Pandas**</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "19243bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f15070",
   "metadata": {},
   "source": [
    "<u>On affiche les 5 premières lignes du DataFrame</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8a1bcdeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>label</th>\n",
       "      <th>pca_features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Clementine</td>\n",
       "      <td>[5.2405386, -1.6420962, 19.637547, 7.7231736, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Strawberry</td>\n",
       "      <td>[7.6019435, 25.94066, -7.2671494, 0.48385996, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Banana</td>\n",
       "      <td>[-25.41924, -2.742938, -1.231952, 10.927477, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Clementine</td>\n",
       "      <td>[7.4443026, -5.86748, 24.184364, -6.5451164, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>file:/home/kilian/workspaces/workspace-data/OC...</td>\n",
       "      <td>Banana</td>\n",
       "      <td>[-25.570768, -3.2196324, -2.7823904, -1.531308...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path       label  \\\n",
       "0  file:/home/kilian/workspaces/workspace-data/OC...  Clementine   \n",
       "1  file:/home/kilian/workspaces/workspace-data/OC...  Strawberry   \n",
       "2  file:/home/kilian/workspaces/workspace-data/OC...      Banana   \n",
       "3  file:/home/kilian/workspaces/workspace-data/OC...  Clementine   \n",
       "4  file:/home/kilian/workspaces/workspace-data/OC...      Banana   \n",
       "\n",
       "                                        pca_features  \n",
       "0  [5.2405386, -1.6420962, 19.637547, 7.7231736, ...  \n",
       "1  [7.6019435, 25.94066, -7.2671494, 0.48385996, ...  \n",
       "2  [-25.41924, -2.742938, -1.231952, 10.927477, 2...  \n",
       "3  [7.4443026, -5.86748, 24.184364, -6.5451164, 1...  \n",
       "4  [-25.570768, -3.2196324, -2.7823904, -1.531308...  "
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2794fca",
   "metadata": {},
   "source": [
    "<u>On valide que la dimension du vecteur de caractéristiques des images est bien de dimension 1280 (si présent) et de dimension 26 pour l'ACP</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "0bb933b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280,)\n",
      "26\n"
     ]
    }
   ],
   "source": [
    "# print(df.loc[0,'features'].shape)\n",
    "print(len(df.loc[0,'pca_features']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe70b7a",
   "metadata": {},
   "source": [
    "Nous venons de valider le processus sur un jeu de données allégé en local <br />\n",
    "où nous avons simulé un cluster de machines en répartissant la charge de travail <br />\n",
    "sur différents cœurs de processeur au sein d'une même machine.\n",
    "\n",
    "Nous allons maintenant généraliser le processus en déployant notre solution <br />\n",
    "sur un réel cluster de machines et nous travaillerons désormais sur la totalité <br />\n",
    "des 22688 images de notre dossier \"Test\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f0f7c1",
   "metadata": {},
   "source": [
    "# 4. Déploiement de la solution sur le cloud\n",
    "\n",
    "Maintenant que nous avons vérifié que notre solution fonctionne, <br />\n",
    "il est temps de la <u>déployer à plus grande échelle sur un vrai cluster de machines</u>.\n",
    "\n",
    "**Attention**, *je travaille sous Linux avec une version Ubuntu, <br />\n",
    "les commandes décrites ci-dessous sont donc réalisées <br />\n",
    "exclusivement dans cet environnement.*\n",
    "\n",
    "<u>Plusieurs contraintes se posent</u> :\n",
    " 1. Quel prestataire de Cloud choisir ?\n",
    " 2. Quelles solutions de ce prestataire adopter ?\n",
    " 3. Où stocker nos données ?\n",
    " 4. Comment configurer nos outils dans ce nouvel environnement ?\n",
    " \n",
    "## 4.1 Choix du prestataire cloud : AWS\n",
    "\n",
    "Le prestataire le plus connu et qui offre à ce jour l'offre <br />\n",
    "la plus large dans le cloud computing est **Amazon Web Services** (AWS).<br />\n",
    "Certaines de leurs offres sont parfaitement adaptées à notre problématique <br />\n",
    "et c'est la raison pour laquelle j'utiliserai leurs services.\n",
    "\n",
    "L'objectif premier est de pouvoir, grâce à AWS, <u>louer de la puissance de calcul à la demande</u>. <br />\n",
    "L'idée étant de pouvoir, quel que soit la charge de travail, <br />\n",
    "obtenir suffisamment de puissance de calcul pour pouvoir traiter nos images, <br />\n",
    "même si le volume de données venait à fortement augmenter.\n",
    "\n",
    "De plus, la capacité d'utiliser cette puissance de calcul à la demande <br />\n",
    "permet de diminuer drastiquement les coûts si l'on compare les coûts d'une location <br />\n",
    "de serveur complet sur une durée fixe (1 mois, 1 année par exemple).\n",
    "\n",
    "## 4.2 Choix de la solution technique : EMR\n",
    "\n",
    "<u>Plusieurs solutions s'offre à nous</u> :\n",
    "1. Solution **IAAS** (Infrastructure AS A Service)\n",
    " - Dans cette configuration **AWS** met à notre disposition des serveurs vierges <br />\n",
    "   sur lequel nous avons un accès en administrateur, ils sont nommés **instance EC2**.<br />\n",
    "   Pour faire simple, nous pouvons avec cette solution reproduire pratiquement <br />\n",
    "   à l'identique la solution mis en œuvre en local sur notre machine.<br />\n",
    "   <u>On installe nous-même l'intégralité des outils puis on exécute notre script</u> :\n",
    "  - Installation de **Spark**, **Java** etc.\n",
    "  - Installation de **Python** (via Anaconda par exemple)\n",
    "  - Installation de **Jupyter Notebook**\n",
    "  - Installation des **librairies complémentaires**\n",
    "  - Il faudra bien évidement veiller à **implémenter les librairies \n",
    "    nécessaires à toutes les machines (workers) du cluster**\n",
    "  - <u>Avantages</u> :\n",
    "      - Liberté totale de mise en œuvre de la solution\n",
    "      - Facilité de mise en œuvre à partir d'un modèle qui s'exécute en local sur une machine Linux\n",
    "  - <u>Inconvénients</u> :\n",
    "      - Cronophage\n",
    "          - Nécessité d'installer et de configurer toute la solution\n",
    "      - Possible problèmes techniques à l'installation des outils (des problématiques qui <br />\n",
    "        n'existaient pas en local sur notre machine peuvent apparaitre sur le serveur EC2)\n",
    "      - Solution non pérenne dans le temps, il faudra veiller à la mise à jour des outils <br />\n",
    "        et éventuellement devoir réinstaller Spark, Java etc. \n",
    "2. Solution **PAAS** (Plateforme As A Service)\n",
    " - **AWS** fournit énormément de services différents, dans l'un de ceux-là <br />\n",
    "   il existe une offre qui permet de louer des **instances EC2** <br />\n",
    "   avec des applications préinstallées et configurées : il s'agit du **service EMR**.\n",
    " - **Spark** y sera déjà installé\n",
    " - Possibilité de demander l'installation de **Tensorflow** ainsi que **JupyterHub**\n",
    " - Possibilité d'indiquer des **packages complémentaires** à installer <br />\n",
    "   à l'initialisation du serveur **sur l'ensemble des machines du cluster**.\n",
    " - <u>Avantages</u> :\n",
    "     - Facilité de mise en œuvre\n",
    "         - Il suffit de très peu de configuration pour obtenir <br />\n",
    "           un environnement parfaitement fonctionnel\n",
    "     - Rapidité de mise en œuvre\n",
    "         - Une fois la première configuration réalisée, il est très facile <br />\n",
    "           et très rapide de recréer des clusters à l'identique qui seront <br />\n",
    "           disponibles presque instantanément (le temps d'instancier les <br />\n",
    "           serveurs soit environ 15/20 minutes)\n",
    "     - Solutions matérielless et logicielles optimisées par les ingénieurs d'AWS\n",
    "         - On sait que les versions installées vont fonctionner <br />\n",
    "           et que l'architecture proposée est optimisée\n",
    "     - Stabilité de la solution\n",
    "    - Solution évolutive\n",
    "        Il est facile d’obtenir à chaque nouvelle instanciation une version à jour <br />\n",
    "        de chaque package, en étant garanti de leur compatibilité avec le reste de l’environnement.\n",
    "  - Plus sécurisé\n",
    "\t- Les éventuels patchs de sécurité seront automatiquement mis à jour <br />\n",
    "      à chaque nouvelle instanciation du cluster EMR.\n",
    " - <u>Inconvénients</u> :\n",
    "     - Peut-être un certain manque de liberté sur la version des packages disponibles ? <br />\n",
    "       Même si je n'ai pas constaté ce problème.\n",
    "   \n",
    "\n",
    "Je retiens la solution **PAAS** en choisissant d'utiliser <br />\n",
    "le service **EMR** d'Amazon Web Services.<br />\n",
    "Je la trouve plus adaptée à notre problématique et permet <br />\n",
    "une mise en œuvre qui soit à la fois plus rapide et <br />\n",
    "plus efficace que la solution IAAS.\n",
    "\n",
    "## 4.3 Choix de la solution de stockage des données : Amazon S3\n",
    "\n",
    "<u>Amazon propose une solution très efficace pour la gestion du stockage des données</u> : **Amazon S3**. <br />\n",
    "S3 pour Amazon Simple Storage Service.\n",
    "\n",
    "Il pourrait être tentant de stocker nos données sur l'espace alloué par le serveur **EC2**, <br />\n",
    "mais si nous ne prenons aucune mesure pour les sauvegarder ensuite sur un autre support, <br />\n",
    "<u>les données seront perdues</u> lorsque le serveur sera résilié (on résilie le serveur lorsqu'on <br />\n",
    "ne s'en sert pas pour des raisons de coût).<br />\n",
    "De fait, si l'on décide d'utiliser l'espace disque du serveur EC2 il faudra imaginer <br />\n",
    "une solution pour sauvegarder les données avant la résiliation du serveur.\n",
    "De plus, nous serions exposés à certaines problématiques si nos données venaient à <br />\n",
    "**saturer** l'espace disponible de nos serveurs (ralentissements, disfonctionnements).\n",
    "\n",
    "<u>Utiliser **Amazon S3** permet de s'affranchir de toutes ces problématiques</u>. <br />\n",
    "L'espace disque disponible est **illimité**, et il est **indépendant de nos serveurs EC2**. <br />\n",
    "L'accès aux données est **très rapide** car nous restons dans l'environnement d'AWS <br />\n",
    "et nous prenons soin de <u>choisir la même région pour nos serveurs **EC2** et **S3**</u>.\n",
    "\n",
    "De plus, comme nous le verrons <u>il est possible d'accéder aux données sur **S3** <br />\n",
    "    de la même manière que l'on **accède aux données sur un disque local**</u>.<br />\n",
    "Nous utiliserons simplement un **PATH au format s3://...** .\n",
    "\n",
    "## 4.4 Configuration de l'environnement de travail\n",
    "\n",
    "La première étape est d'installer et de configurer [**AWS Cli**](https://aws.amazon.com/fr/cli/),<br />\n",
    "il s'agit de l'**interface en ligne de commande d'AWS**.<br />\n",
    "Elle nous permet d'**interagir avec les différents services d'AWS**, comme **S3** par exemple.\n",
    "\n",
    "Pour pouvoir utiliser **AWS Cli**, il faut le configurer en créant préalablement <br />\n",
    "un utilisateur à qui on donnera les autorisations dont nous aurons besoin.<br />\n",
    "Dans ce projet il faut que l'utilisateur ait à minima un contrôle total sur le service S3.\n",
    "\n",
    "<u>La gestion des utilisateurs et de leurs droits s'effectue via le service **IAM**</u> d'AWS.\n",
    "\n",
    "Une fois l'utilisateur créé et ses autorisations configurées nous créons une **paire de clés** <br />\n",
    "qui nous permettra de nous **connecter sans à avoir à devoir saisir systématiquement notre login/mot de passe**.<br />\n",
    "\n",
    "Il faut également configurer l'**accès SSH** à nos futurs serveurs EC2. <br />\n",
    "Ici aussi, via un système de clés qui nous dispense de devoir nous authentifier \"à la main\" à chaque connexion.\n",
    "\n",
    "Toutes ses étapes de configuration sont parfaitement décrites <br />\n",
    "dans le cours du projet: [Réalisez des calculs distribués sur des données massives / Découvrez Amazon Web Services](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308686-decouvrez-amazon-web-services#/id/r-4355822)\n",
    "\n",
    "## 4.5 Upload de nos données sur S3\n",
    "\n",
    "Nos outils sont configurés. <br />\n",
    "Il faut maintenant uploader nos données de travail sur Amazon S3.\n",
    "\n",
    "Ici aussi les étapes sont décrites avec précision <br />\n",
    "dans le cours [Réalisez des calculs distribués sur des données massives / Stockez des données sur S3](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308691-stockez-des-donnees-sur-s3)\n",
    "\n",
    "Je décide de n'uploader que les données contenues dans le dossier **Test** du [jeu de données du projet](https://www.kaggle.com/moltean/fruits/download)\n",
    "\n",
    "\n",
    "La première étape consiste à **créer un bucket sur S3** <br />\n",
    "dans lequel nous uploaderons les données du projet:\n",
    "- **aws s3 mb s3://p8-data**\n",
    "\n",
    "On vérifie que le bucket à bien été créé\n",
    "- **aws s3 ls**\n",
    " - Si le nom du bucket s'affiche alors c'est qu'il a été correctement créé.\n",
    "\n",
    "On copie ensuite le contenu du dossier \"**Test**\" <br />\n",
    "dans un répertoire \"**Test**\" sur notre bucket \"**p8-data**\":\n",
    "1. On se place à l'intérieur du répertoire **Test**\n",
    "2. **aws sync . s3://p8-data/Test**\n",
    "\n",
    "La commande **sync** est utile pour synchroniser deux répertoires.\n",
    "\n",
    "<u>Nos données du projet sont maintenant disponibles sur Amazon S3</u>.\n",
    "\n",
    "## 4.6 Configuration du serveur EMR\n",
    "\n",
    "Une fois encore, le cours [Réalisez des calculs distribués sur des données massives / Déployez un cluster de calculs distribués](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues) <br /> détaille l'essentiel des étapes pour lancer un cluster avec **EMR**.\n",
    "\n",
    "<u>Je détaillerai ici les étapes particulières qui nous permettent <br />\n",
    "de configurer le serveur selon nos besoins</u> :\n",
    "\n",
    "1. Cliquez sur Créer un cluster\n",
    "![Créer un cluster](img/EMR_creer.png)\n",
    "2. Cliquez sur Accéder aux options avancées\n",
    "![Créer un cluster](img/EMR_options_avancees.png)\n",
    "\n",
    "### 4.6.1 Étape 1 : Logiciels et étapes\n",
    "\n",
    "#### 4.6.1.1 Configuration des logiciels\n",
    "\n",
    "<u>Sélectionnez les packages dont nous aurons besoin comme dans la capture d'écran</u> :\n",
    "1. Nous sélectionnons la dernière version d'**EMR**, soit la version **6.3.0** au moment où je rédige ce document\n",
    "2. Nous cochons bien évidement **Hadoop** et **Spark** qui seront préinstallés dans leur version la plus récente\n",
    "3. Nous aurons également besoin de **TensorFlow** pour importer notre modèle et réaliser le **transfert learning**\n",
    "4. Nous travaillerons enfin avec un **notebook Jupyter** via l'application **JupyterHub**<br />\n",
    " - Comme nous le verrons dans un instant nous allons <u>paramétrer l'application afin que les notebooks</u>, <br />\n",
    "   comme le reste de nos données de travail, <u>soient enregistrés directement sur S3</u>.\n",
    "![Créer un cluster](img/EMR_configuration_logiciels.png)\n",
    "\n",
    "#### 4.6.1.2 Modifier les paramètres du logiciel\n",
    "\n",
    "<u>Paramétrez la persistance des notebooks créés et ouvert via JupyterHub</u> :\n",
    "- On peut à cette étape effectuer des demandes de paramétrage particulières sur nos applications. <br />\n",
    "  L'objectif est, comme pour le reste de nos données de travail, <br />\n",
    "  d'éviter toutes les problématiques évoquées précédemment. <br />\n",
    "  C'est l'objectif à cette étape, <u>nous allons enregistrer <br />\n",
    "  et ouvrir les notebooks</u> non pas sur l'espace disque de  l'instance EC2 (comme <br />\n",
    "  ce serait le cas dans la configuration par défaut de JupyterHub) mais <br />\n",
    "  <u>directement sur **Amazon S3**</u>.\n",
    "- <u>deux solutions sont possibles pour réaliser cela</u> :\n",
    " 1. Créer un **fichier de configuration JSON** que l'on **upload sur S3** et on indique ensuite le chemin d’accès au fichier JSON\n",
    " 2. Rentrez directement la configuration au format JSON\n",
    " \n",
    "J'ai personnellement créé un fichier JSON lors de la création de ma première instance EMR, <br />\n",
    "puis lorsqu'on décide de cloner notre serveur pour en recréer un facilement à l'identique, <br />\n",
    "la configuration du fichier JSON se retrouve directement copié comme dans la capture ci-dessous.\n",
    "\n",
    "<u>Voici le contenu de mon fichier JSON</u> :  [{\"classification\":\"jupyter-s3-conf\",\"properties\":{\"s3.persistence.bucket\":\"p8-data\",\"s3.persistence.enabled\":\"true\"}}]\n",
    " Appuyez ensuite sur \"**Suivant**\"\n",
    "![Modifier les paramètres du logiciel](img/EMR_parametres_logiciel.png)\n",
    "\n",
    "### 4.6.2 Étape 2 : Matériel\n",
    "\n",
    "A cette étape, laissez les choix par défaut. <br />\n",
    "<u>L'important ici est la sélection de nos instances</u> :\n",
    "\n",
    "1. je choisi les instances de type **M5** qui sont des **instances de type équilibrés**\n",
    "2. je choisi le type **xlarge** qui est l'instance la **moins onéreuse disponible**\n",
    " [Plus d'informations sur les instances M5 Amazon EC2](https://aws.amazon.com/fr/ec2/instance-types/m5/)\n",
    "3. Je sélectionne **1 instance Maître** (le driver) et **2 instances Principales** (les workeurs) <br />\n",
    "   soit **un total de 3 instance EC2**.\n",
    "![Choix du materiel](img/EMR_materiel.png)\n",
    "\n",
    "### 4.6.3 Étape 3 : Paramètres de cluster généraux\n",
    "\n",
    "#### 4.6.3.1 Options générales\n",
    "<u>La première chose à faire est de donner un nom au cluster</u> :<br />\n",
    "*J'ai également décoché \"Protection de la résiliation\" pour des raisons pratiques.*\n",
    "    \n",
    "![Nom du Cluster](img/EMR_nom_cluster.png)\n",
    "\n",
    "#### 4.6.3.2 Actions d'amorçage\n",
    "\n",
    "Nous allons à cette étape **choisir les packages manquants à installer** et qui <br />\n",
    "nous serons utiles dans l'exécution de notre notebook.<br />\n",
    "<u>L'avantage de réaliser cette étape maintenant est que les packages <br />\n",
    "installés le seront sur l'ensemble des machines du cluster</u>.\n",
    "\n",
    "La procédure pour créer le fichier **bootstrap** qui contient <br />\n",
    "l'ensemble des instructions permettant d'installer tous <br />\n",
    "les packages dont nous aurons besoin est expliqué dans <br />\n",
    "le cours [Réalisez des calculs distribués sur des données massives / Bootstrapping](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356490)\n",
    "\n",
    "Nous créons donc un fichier nommé \"**bootstrap-emr.sh**\" que nous <u>uploadons <br />\n",
    "sur S3</u>(je l’installe à la racine de mon **bucket \"p8-data\"**) et nous l'ajoutons <br />\n",
    "comme indiqué dans la capture d'écran ci-dessous:\n",
    "![Actions d'amorcage](img/EMR_amorcage.png)\n",
    "\n",
    "Voici le contenu du fichier **bootstrap-emr.sh**<br />\n",
    "Comme on peut le constater il s'agit simplement de commande \"**pip install**\" <br />\n",
    "pour **installer les bibliothèques manquantes** comme réalisé en local.<br />\n",
    "Une fois encore, <u>il est nécessaire de réaliser ces actions à cette étape</u> <br />\n",
    "pour que <u>les packages soient installés sur l'ensemble des machines du cluster</u> <br />\n",
    "et non pas uniquement sur le driver, comme cela serait le cas si nous exécutions <br />\n",
    "ces commandes directement dans le notebook JupyterHub ou dans la console EMR (connecté au driver).\n",
    "![Contenu du fichier bootstrap](img/EMR_bootstrap.png)\n",
    "\n",
    "**setuptools** et **pip** sont mis à jour pour éviter une problématique <br />\n",
    "avec l'installation du package **pyarrow**.<br />\n",
    "**Pandas** a eu droit à une mise à jour majeur (1.3.0) il y a moins d'une semaine <br />\n",
    "au moment de la rédaction de ce notebook, et la nouvelle version de **Pandas** <br />\n",
    "nécessite une version plus récente de **Numpy** que la version installée par <br />\n",
    "défaut (1.16.5) à l'initialisation des instances **EC2**. <u>Il ne semble pas <br />\n",
    "possible d'imposer une autre version de Numpy que celle installé par <br />\n",
    "défaut</u> même si on force l'installation d'une version récente de **Numpy** <br />\n",
    "(en tout cas, ni simplement ni intuitivement).<br />\n",
    "La mise à jour étant très récente <u>la version de **Numpy** n'est pas encore <br />\n",
    "mise à jour sur **EC2**</u> mais on peut imaginer que ce sera le cas très rapidement <br />\n",
    "et il ne sera plus nécessaire d'imposer une version spécifique de **Pandas**.<br />\n",
    "En attendant, je demande <u>l'installation de l'avant dernière version de **Pandas (1.2.5)**</u>\n",
    "\n",
    "On clique ensuite sur ***Suivant***\n",
    "\n",
    "### 4.6.4 Étape 4 : Sécurité\n",
    "\n",
    "#### 4.6.4.1 Options de sécurité\n",
    "\n",
    "A cette étape nous sélectionnons la **paire de clés EC2** créé précédemment. <br />\n",
    "Elle nous permettra de se connecter en **ssh** à nos **instances EC2** <br />\n",
    "sans avoir à entrer nos login/mot de passe.<br />\n",
    "On laisse les autres paramètres par défaut. <br />\n",
    "Et enfin, on clique sur \"***Créer un cluster***\"\n",
    " \n",
    "![EMR Sécurité](img/EMR_securite.png)\n",
    "\n",
    "## 4.7 Instanciation du serveur\n",
    "\n",
    "Il ne nous reste plus qu'à attendre que le serveur soit prêt. <br />\n",
    "Cette étape peut prendre entre **15 et 20 minutes**.\n",
    "\n",
    "<u>Plusieurs étapes s'enchaîne, on peut suivre l'avancé du statut du **cluster EMR**</u> :\n",
    "\n",
    "![Instanciation étape 1](img/EMR_instanciation_01.png)\n",
    "![Instanciation étape 2](img/EMR_instanciation_02.png)\n",
    "![Instanciation étape 3](img/EMR_instanciation_03.png)\n",
    "\n",
    "<u>Lorsque le statut affiche en vert: \"**En attente**\" cela signifie que l'instanciation <br />\n",
    "s'est bien déroulée et que notre serveur est prêt à être utilisé</u>. \n",
    "\n",
    "## 4.8 Création du tunnel SSH à l'instance EC2 (Maître)\n",
    "\n",
    "### 4.8.1 Création des autorisations sur les connexions entrantes\n",
    "\n",
    "<u>Nous souhaitons maintenant pouvoir accéder à nos applications</u> :\n",
    " - **JupyterHub** pour l'exécution de notre notebook\n",
    " - **Serveur d'historique Spark** pour le suivi de l'exécution <br />\n",
    "   des tâches de notre script lorsqu'il sera lancé\n",
    " \n",
    "Cependant, <u>ces applications ne sont accessibles que depuis le réseau local du driver</u>, <br />\n",
    "et pour y accéder nous devons **créer un tunnel SSH vers le driver**.\n",
    "\n",
    "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
    "<u>Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
    "il faut modifier le **groupe de sécurité EC2 du driver**</u>.\n",
    "\n",
    "Cette étape est décrite dans le cours [Réalisez des calculs distribués sur des données massives / Lancement d'une application à partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308696-deployez-un-cluster-de-calculs-distribues#/id/r-4356512): \n",
    "\n",
    "*Il faudra que l'on se connecte en SSH au driver de notre cluster. <br />\n",
    "Par défaut, ce driver se situe derrière un firewall qui bloque l'accès en SSH. <br />\n",
    "Pour ouvrir le port 22 qui correspond au port sur lequel écoute le serveur SSH, <br />\n",
    "il faut modifier le groupe de sécurité EC2 du driver. Sur la page de la console <br />\n",
    "consacrée à EC2, dans l'onglet \"Réseau et sécurité\", cliquez sur \"Groupes de sécurité\". <br />\n",
    "Vous allez devoir modifier le groupe de sécurité d’ElasticMapReduce-Master. <br />\n",
    "Dans l'onglet \"Entrant\", ajoutez une règle SSH dont la source est \"N'importe où\" <br />\n",
    "(ou \"Mon IP\" si vous disposez d'une adresse IP fixe).*\n",
    "\n",
    "![Configuration autorisation ports entrants pour ssh](img/EMR_config_ssh_01.png)\n",
    "\n",
    "<u>Une fois cette étape réalisée vous devriez avoir une configuration semblable à la mienne</u> :\n",
    "\n",
    "![Configuration ssh terminée](img/EMR_config_ssh_02.png)\n",
    "\n",
    "### 4.8.2 Création du tunnel ssh vers le Driver\n",
    "\n",
    "On peut maintenant établir le **tunnel SSH** vers le **Driver**. <br />\n",
    "Pour cela on récupère les informations de connexion fournis par Amazon <br />\n",
    "depuis la page du service EMR / Cluster / onglet Récapitulatif en <br />\n",
    "cliquant sur \"**Activer la connexion Web**\"\n",
    "\n",
    "![Activer la connexion Web](img/EMR_tunnel_ssh_01.png)\n",
    "\n",
    "<u>On récupère ensuite la commande fournis par Amazon pour **établir le tunnel SSH**</u> :\n",
    "\n",
    "![Récupérer la commande pour établir le tunnel ssh](img/EMR_tunnel_ssh_02.png)\n",
    "\n",
    "<u>Dans mon cas, la commande ne fonctionne pas tel</u> quel et j'ai du **l'adapter à ma configuration**. <br />\n",
    "La **clé ssh** se situe dans un dossier \"**.ssh**\" elle-même située dans <br />\n",
    "mon **répertoire personnel** dont le symbole est, sous Linux, identifié par un tilde \"**~**\".\n",
    "\n",
    "Ayant suivi le cours [Réalisez des calculs distribués sur des données massives / Lancement d'une application à partir du driver](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives) <br />\n",
    "j'ai choisi d'utiliser le port **5555** au lieu du **8157**, même si le choix n'est pas très important.<br />\n",
    "    j'ai également rencontré un <u>problème de compatibilité</u> avec <br />\n",
    "l'argument \"**-N**\" (liste des arguments et leur significations <br />\n",
    "disponibles [ici](https://explainshell.com/explain?cmd=ssh+-L+-N+-f+-l+-D)) j'ai décidé de simplement le supprimer.\n",
    "\n",
    "<u>Finalement, j'utilise la commande suivante dans un terminal pour établir <br />\n",
    "    mon tunnel ssh (seul l'URL change d'une instance à une autre)</u> : <br />\n",
    "\"**ssh -i ~/.ssh/p8-ec2.pem -D 5555 hadoop@ec2-35-180-91-39.eu-west-3.compute.amazonaws.com**\"\n",
    "\n",
    "<u>On inscrit \"**yes**\" pour valider la connexion et si <br />\n",
    "    la connexion est établit on obtient le résultat suivant</u> :\n",
    "\n",
    "![Création du tunnel SSH](img/EMR_connexion_ssh_01.png)\n",
    "\n",
    "Nous avons **correctement établi le tunnel ssh avec le driver** sur le port \"5555\".\n",
    "\n",
    "### 4.8.3 Configuration de FoxyProxy\n",
    "\n",
    "Une dernière étape est nécessaire pour accéder à nos applications, <br />\n",
    "en demandant à notre navigateur d'emprunter le tunnel ssh.<br />\n",
    "J'utilise pour cela **FoxyProxy**.\n",
    "[Une fois encore, vous pouvez utiliser le cours pour le configurer](https://openclassrooms.com/fr/courses/4297166-realisez-des-calculs-distribues-sur-des-donnees-massives/4308701-realisez-la-maintenance-dun-cluster#/id/r-4356554).\n",
    "\n",
    "Sinon, ouvrez la configuration de **FoxyProxy** et <u>cliquez sur **Ajouter**</u> en haut à gauche <br />\n",
    "puis renseigner les éléments comme dans la capture ci-dessous :\n",
    "\n",
    "![Configuration FoxyProxy Etape 1](img/EMR_foxyproxy_config_01.png)\n",
    "\n",
    "<u>On obtient le résultat ci-dessous</u> :\n",
    "\n",
    "![Configuration FoxyProxy Etape 2](img/EMR_foxyproxy_config_02.png)\n",
    "\n",
    "\n",
    "### 4.8.4 Accès aux applications du serveur EMR via le tunnel ssh\n",
    "\n",
    "\n",
    "<u>Avant d'établir notre **tunnel ssh** nous avions ça</u> :\n",
    "\n",
    "![avant tunnel ssh](img/EMR_tunnel_ssh_avant.png)\n",
    "\n",
    "<u>On active le **tunnel ssh** comme vu précédemment puis on demande <br />\n",
    "à notre navigateur de l'utiliser avec **FoxyProxy**</u> :\n",
    "\n",
    "![FoxyProxy activation](img/EMR_foxyproxy_activation.png)\n",
    "\n",
    "<u>On peut maintenant s'apercevoir que plusieurs applications nous sont accessibles</u> :\n",
    "\n",
    "![avant tunnel ssh](img/EMR_tunnel_ssh_apres.png)\n",
    "\n",
    "## 4.9 Connexion au notebook JupyterHub\n",
    "\n",
    "Pour se connecter à **JupyterHub** en vue d'exécuter notre **notebook**, <br />\n",
    "il faut commencer par <u>cliquer sur l'application **JupyterHub**</u> apparu <br />\n",
    "depuis que nous avons configuré le **tunnel ssh** et **foxyproxy** sur <br />\n",
    "notre navigateur (actualisez la page si ce n’est pas le cas).\n",
    "\n",
    "![Démarrage de JupyterHub](img/EMR_jupyterhub_connexion_01.png)\n",
    "\n",
    "On passe les éventuels avertissements de sécurité puis <br />\n",
    "nous arrivons sur une page de connexion.\n",
    "    \n",
    "<u>On se connecte avec les informations par défaut</u> :\n",
    " - <u>login</u>: **jovyan**\n",
    " - <u>password</u>: **jupyter**\n",
    " \n",
    "![Connexion à JupyterHub](img/EMR_jupyterhub_connexion_02.png)\n",
    "\n",
    "Nous arrivons ensuite dans un dossier vierge de notebook.<br />\n",
    "Il suffit d'en créer un en cliquant sur \"**New**\" en haut à droite.\n",
    "\n",
    "![Liste et création des notebook](img/EMR_jupyterhub_creer_notebooks.png)\n",
    "\n",
    "Il est également possible d'en <u>uploader un directement dans notre **bucket S3**</u>.\n",
    "\n",
    "Grace à la <u>**persistance** paramétrée à l'instanciation du cluster <br />\n",
    "nous sommes actuellement dans l'arborescence de notre **bucket S3**</u>\n",
    "\n",
    "![Notebook stockés sur S3](img/EMR_jupyterhub_S3.png)\n",
    "\n",
    "Je décide d'**importer un notebook déjà rédigé en local directement <br />\n",
    "sur S3** et je l'ouvre depuis **l'interface JupyterHub**.\n",
    "\n",
    "## 4.10 Exécution du code\n",
    "\n",
    "Je décide d'exécuter cette partie du code depuis **JupyterHub hébergé sur notre cluster EMR**.<br />\n",
    "Pour ne pas alourdir inutilement les explications du **notebook**, je ne réexpliquerai pas les étapes communes <br />\n",
    "que nous avons déjà vues dans la première partie où l'on a exécuté le code localement sur notre machine virtuelle Ubuntu.\n",
    "\n",
    "<u>Avant de commencer</u>, il faut s'assurer d'utiliser le **kernel pyspark**.\n",
    "\n",
    "**En utilisant ce kernel, une session spark est créé à l'exécution de la première cellule**. <br />\n",
    "Il n'est donc **plus nécessaire d'exécuter le code \"spark = (SparkSession ...\"** comme lors <br />\n",
    "de l'exécution de notre notebook en local sur notre VM Ubuntu."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e759c1e",
   "metadata": {},
   "source": [
    "### 4.10.1 Démarrage de la session Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5f0fbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# L'exécution de cette cellule démarre l'application Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba202f",
   "metadata": {},
   "source": [
    "<u>Affichage des informations sur la session en cours et liens vers Spark UI</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fb788991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%info` not found.\n"
     ]
    }
   ],
   "source": [
    "%%info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ac9832",
   "metadata": {},
   "source": [
    "### 4.10.2 Installation des packages\n",
    "\n",
    "Les packages nécessaires ont été installé via l'étape de **bootstrap** à l'instanciation du serveur.\n",
    "\n",
    "### 4.10.3 Import des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ad562eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import io\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras.applications.mobilenet_v2 import MobileNetV2, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras import Model\n",
    "from pyspark.sql.functions import col, pandas_udf, PandasUDFType, element_at, split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83663cbd",
   "metadata": {},
   "source": [
    "### 4.10.4 Définition des PATH pour charger les images et enregistrer les résultats\n",
    "\n",
    "Nous accédons directement à nos **données sur S3** comme si elles étaient **stockées localement**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46be859d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATH:        s3://p8-data\n",
      "PATH_Data:   s3://p8-data/Test\n",
      "PATH_Result: s3://p8-data/Results\n"
     ]
    }
   ],
   "source": [
    "PATH = 's3://p8-data'\n",
    "PATH_Data = PATH+'/Test'\n",
    "PATH_Result = PATH+'/Results'\n",
    "print('PATH:        '+\\\n",
    "      PATH+'\\nPATH_Data:   '+\\\n",
    "      PATH_Data+'\\nPATH_Result: '+PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf883c20",
   "metadata": {},
   "source": [
    "### 4.10.5 Traitement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffe93f5",
   "metadata": {},
   "source": [
    "#### 4.10.5.1 Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e4b319a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/08/10 14:59:23 WARN FileStreamSink: Assume no metadata directory. Error while looking for metadata directory in the path: s3://p8-data/Test.\n",
      "org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\n",
      "\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n",
      "\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n",
      "\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n",
      "\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n",
      "\tat org.apache.spark.sql.execution.streaming.FileStreamSink$.hasMetadata(FileStreamSink.scala:53)\n",
      "\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:366)\n",
      "\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n",
      "\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n",
      "\tat scala.Option.getOrElse(Option.scala:189)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n",
      "\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    },
    {
     "ename": "Py4JJavaError",
     "evalue": "An error occurred while calling o83.load.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m images \u001b[39m=\u001b[39m spark\u001b[39m.\u001b[39;49mread\u001b[39m.\u001b[39;49mformat(\u001b[39m\"\u001b[39;49m\u001b[39mbinaryFile\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      2\u001b[0m   \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mpathGlobFilter\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m*.jpg\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      3\u001b[0m   \u001b[39m.\u001b[39;49moption(\u001b[39m\"\u001b[39;49m\u001b[39mrecursiveFileLookup\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mtrue\u001b[39;49m\u001b[39m\"\u001b[39;49m) \\\n\u001b[1;32m      4\u001b[0m   \u001b[39m.\u001b[39;49mload(PATH_Data)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyspark/sql/readwriter.py:300\u001b[0m, in \u001b[0;36mDataFrameReader.load\u001b[0;34m(self, path, format, schema, **options)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    299\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(path, \u001b[39mstr\u001b[39m):\n\u001b[0;32m--> 300\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_df(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jreader\u001b[39m.\u001b[39;49mload(path))\n\u001b[1;32m    301\u001b[0m \u001b[39melif\u001b[39;00m path \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    302\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mtype\u001b[39m(path) \u001b[39m!=\u001b[39m \u001b[39mlist\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1316\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1321\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client\u001b[39m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1322\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtarget_id, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname)\n\u001b[1;32m   1325\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n\u001b[1;32m   1326\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(temp_arg, \u001b[39m\"\u001b[39m\u001b[39m_detach\u001b[39m\u001b[39m\"\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pyspark/errors/exceptions/captured.py:169\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdeco\u001b[39m(\u001b[39m*\u001b[39ma: Any, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    168\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 169\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49ma, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkw)\n\u001b[1;32m    170\u001b[0m     \u001b[39mexcept\u001b[39;00m Py4JJavaError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    171\u001b[0m         converted \u001b[39m=\u001b[39m convert_exception(e\u001b[39m.\u001b[39mjava_exception)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/py4j/protocol.py:326\u001b[0m, in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    324\u001b[0m value \u001b[39m=\u001b[39m OUTPUT_CONVERTER[\u001b[39mtype\u001b[39m](answer[\u001b[39m2\u001b[39m:], gateway_client)\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m answer[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m REFERENCE_TYPE:\n\u001b[0;32m--> 326\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JJavaError(\n\u001b[1;32m    327\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    328\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name), value)\n\u001b[1;32m    329\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     \u001b[39mraise\u001b[39;00m Py4JError(\n\u001b[1;32m    331\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error occurred while calling \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m{1}\u001b[39;00m\u001b[39m{2}\u001b[39;00m\u001b[39m. Trace:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{3}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\n\u001b[1;32m    332\u001b[0m         \u001b[39mformat\u001b[39m(target_id, \u001b[39m\"\u001b[39m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m, name, value))\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o83.load.\n: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"s3\"\n\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.$anonfun$checkAndGlobPathIfNecessary$1(DataSource.scala:724)\n\tat scala.collection.immutable.List.map(List.scala:293)\n\tat org.apache.spark.sql.execution.datasources.DataSource$.checkAndGlobPathIfNecessary(DataSource.scala:722)\n\tat org.apache.spark.sql.execution.datasources.DataSource.checkAndGlobPathIfNecessary(DataSource.scala:551)\n\tat org.apache.spark.sql.execution.datasources.DataSource.resolveRelation(DataSource.scala:404)\n\tat org.apache.spark.sql.DataFrameReader.loadV1Source(DataFrameReader.scala:229)\n\tat org.apache.spark.sql.DataFrameReader.$anonfun$load$2(DataFrameReader.scala:211)\n\tat scala.Option.getOrElse(Option.scala:189)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:211)\n\tat org.apache.spark.sql.DataFrameReader.load(DataFrameReader.scala:186)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n\tat java.base/java.lang.Thread.run(Thread.java:829)\n"
     ]
    }
   ],
   "source": [
    "images = spark.read.format(\"binaryFile\") \\\n",
    "  .option(\"pathGlobFilter\", \"*.jpg\") \\\n",
    "  .option(\"recursiveFileLookup\", \"true\") \\\n",
    "  .load(PATH_Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bfeb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+------+--------------------+\n",
      "|                path|   modificationTime|length|             content|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "|s3://p8-data/Test...|2021-07-03 09:00:08|  7353|[FF D8 FF E0 00 1...|\n",
      "|s3://p8-data/Test...|2021-07-03 09:00:08|  7350|[FF D8 FF E0 00 1...|\n",
      "|s3://p8-data/Test...|2021-07-03 09:00:08|  7349|[FF D8 FF E0 00 1...|\n",
      "|s3://p8-data/Test...|2021-07-03 09:00:08|  7348|[FF D8 FF E0 00 1...|\n",
      "|s3://p8-data/Test...|2021-07-03 09:00:09|  7328|[FF D8 FF E0 00 1...|\n",
      "+--------------------+-------------------+------+--------------------+\n",
      "only showing top 5 rows"
     ]
    }
   ],
   "source": [
    "images.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b32ac34",
   "metadata": {},
   "source": [
    "<u>Je ne conserve que le **path** de l'image et j'ajoute <br />\n",
    "    une colonne contenant les **labels** de chaque image</u> :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52ab808",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- path: string (nullable = true)\n",
      " |-- modificationTime: timestamp (nullable = true)\n",
      " |-- length: long (nullable = true)\n",
      " |-- content: binary (nullable = true)\n",
      " |-- label: string (nullable = true)\n",
      "\n",
      "None\n",
      "+------------------------------------------+----------+\n",
      "|path                                      |label     |\n",
      "+------------------------------------------+----------+\n",
      "|s3://p8-data/Test/Watermelon/r_106_100.jpg|Watermelon|\n",
      "|s3://p8-data/Test/Watermelon/r_109_100.jpg|Watermelon|\n",
      "|s3://p8-data/Test/Watermelon/r_108_100.jpg|Watermelon|\n",
      "|s3://p8-data/Test/Watermelon/r_107_100.jpg|Watermelon|\n",
      "|s3://p8-data/Test/Watermelon/r_95_100.jpg |Watermelon|\n",
      "+------------------------------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None"
     ]
    }
   ],
   "source": [
    "images = images.withColumn('label', element_at(split(images['path'], '/'),-2))\n",
    "print(images.printSchema())\n",
    "print(images.select('path','label').show(5,False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f15b199",
   "metadata": {},
   "source": [
    "#### 4.10.5.2 Préparation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c7165",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224.h5\n",
      "\r\n",
      "    8192/14536120 [..............................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      " 4202496/14536120 [=======>......................] - ETA: 0s\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\n",
      "14540800/14536120 [==============================] - 0s 0us/step"
     ]
    }
   ],
   "source": [
    "model = MobileNetV2(weights='imagenet',\n",
    "                    include_top=True,\n",
    "                    input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9bc650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d497f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "brodcast_weights = sc.broadcast(new_model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0bf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 1280)         0           out_relu[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 2,257,984\n",
      "Trainable params: 2,223,872\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "new_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8fe2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def model_fn():\n",
    "    \"\"\"\n",
    "    Returns a MobileNetV2 model with top layer removed \n",
    "    and broadcasted pretrained weights.\n",
    "    \"\"\"\n",
    "    model = MobileNetV2(weights='imagenet',\n",
    "                        include_top=True,\n",
    "                        input_shape=(224, 224, 3))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "    new_model = Model(inputs=model.input,\n",
    "                  outputs=model.layers[-2].output)\n",
    "    new_model.set_weights(brodcast_weights.value)\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c032f135",
   "metadata": {},
   "source": [
    "#### 4.10.5.3 Définition du processus de chargement des images <br/> et application de leur featurisation à travers l'utilisation de pandas UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933100cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/pandas/functions.py:392: UserWarning: In Python 3.6+ and Spark 3.0+, it is preferred to specify type hints for pandas UDF instead of specifying pandas UDF type which will be deprecated in the future releases. See SPARK-28264 for more details."
     ]
    }
   ],
   "source": [
    "def preprocess(content):\n",
    "    \"\"\"\n",
    "    Preprocesses raw image bytes for prediction.\n",
    "    \"\"\"\n",
    "    img = Image.open(io.BytesIO(content)).resize([224, 224])\n",
    "    arr = img_to_array(img)\n",
    "    return preprocess_input(arr)\n",
    "\n",
    "def featurize_series(model, content_series):\n",
    "    \"\"\"\n",
    "    Featurize a pd.Series of raw images using the input model.\n",
    "    :return: a pd.Series of image features\n",
    "    \"\"\"\n",
    "    input = np.stack(content_series.map(preprocess))\n",
    "    preds = model.predict(input)\n",
    "    # For some layers, output features will be multi-dimensional tensors.\n",
    "    # We flatten the feature tensors to vectors for easier storage in Spark DataFrames.\n",
    "    output = [p.flatten() for p in preds]\n",
    "    return pd.Series(output)\n",
    "\n",
    "@pandas_udf('array<float>', PandasUDFType.SCALAR_ITER)\n",
    "def featurize_udf(content_series_iter):\n",
    "    '''\n",
    "    This method is a Scalar Iterator pandas UDF wrapping our featurization function.\n",
    "    The decorator specifies that this returns a Spark DataFrame column of type ArrayType(FloatType).\n",
    "\n",
    "    :param content_series_iter: This argument is an iterator over batches of data, where each batch\n",
    "                              is a pandas Series of image data.\n",
    "    '''\n",
    "    # With Scalar Iterator pandas UDFs, we can load the model once and then re-use it\n",
    "    # for multiple data batches.  This amortizes the overhead of loading big models.\n",
    "    model = model_fn()\n",
    "    for content_series in content_series_iter:\n",
    "        yield featurize_series(model, content_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23206e8",
   "metadata": {},
   "source": [
    "#### 4.10.5.4 Exécutions des actions d'extractions de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d760c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# spark.conf.set(\"spark.sql.execution.arrow.maxRecordsPerBatch\", \"1024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e07fd68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_df = images.repartition(24).select(col(\"path\"),\n",
    "                                            col(\"label\"),\n",
    "                                            featurize_udf(\"content\").alias(\"features\")\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "06a930b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://p8-data/Results"
     ]
    }
   ],
   "source": [
    "print(PATH_Result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c53ddd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_df.write.mode(\"overwrite\").parquet(PATH_Result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fe01b72",
   "metadata": {},
   "source": [
    "### 4.10.6 Chargement des données enregistrées et validation du résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db18a784",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_parquet(PATH_Result, engine='pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d750d2a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           path  ...                                           features\n",
      "0    s3://p8-data/Test/Watermelon/r_174_100.jpg  ...  [0.0059991637, 0.44703647, 0.0, 0.0, 3.3713572...\n",
      "1  s3://p8-data/Test/Pineapple Mini/128_100.jpg  ...  [0.0146466885, 4.080593, 0.055877004, 0.0, 0.0...\n",
      "2  s3://p8-data/Test/Pineapple Mini/137_100.jpg  ...  [0.0, 4.9659867, 0.0, 0.0, 0.0, 0.0, 0.5144821...\n",
      "3      s3://p8-data/Test/Watermelon/275_100.jpg  ...  [0.22511952, 0.07235509, 0.0, 0.0, 1.690149, 0...\n",
      "4      s3://p8-data/Test/Watermelon/271_100.jpg  ...  [0.3286234, 0.18830013, 0.0, 0.0, 1.9123534, 0...\n",
      "\n",
      "[5 rows x 3 columns]"
     ]
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b29205ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280,)"
     ]
    }
   ],
   "source": [
    "df.loc[0,'features'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4fba6455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22688, 3)"
     ]
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72974aab",
   "metadata": {},
   "source": [
    "<u>On peut également constater la présence des fichiers <br />\n",
    "    au format \"**parquet**\" sur le **serveur S3**</u> :\n",
    "\n",
    "![Affichage des résultats sur S3](img/S3_Results.png)\n",
    "\n",
    "## 4.11 Suivi de l'avancement des tâches avec le Serveur d'Historique Spark\n",
    "\n",
    "Il est possible de voir l'avancement des tâches en cours <br />\n",
    "avec le **serveur d'historique Spark**.\n",
    "\n",
    "![Accès au serveur d'historique spark](img/EMR_serveur_historique_spark_acces.png)\n",
    "\n",
    "**Il est également possible de revenir et d'étudier les tâches <br />\n",
    "qui ont été réalisé, afin de debugger, optimiser les futurs <br />\n",
    "tâches à réaliser.**\n",
    "\n",
    "<u>Lorsque la commande \"**features_df.write.mode(\"overwrite\").parquet(PATH_Result)**\" <br />\n",
    "était en cours, nous pouvions observer son état d'avancement</u> :\n",
    "\n",
    "![Progression execution script](img/EMR_jupyterhub_avancement.png)\n",
    "\n",
    "<u>Le **serveur d'historique Spark** nous permet une vision beaucoup plus précise <br />\n",
    "de l'exécution des différentes tâche sur les différentes machines du cluster</u> :\n",
    "\n",
    "![Suivi des tâches spark](img/EMR_SHSpark_01.png)\n",
    "\n",
    "On peut également constater que notre cluster de calcul a mis <br />\n",
    "un tout petit peu **moins de 8 minutes** pour traiter les **22 688 images**.\n",
    "\n",
    "![Temps de traitement](img/EMR_SHSpark_02.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22d65bf",
   "metadata": {},
   "source": [
    "## 4.12 Résiliation de l'instance EMR\n",
    "\n",
    "Notre travail est maintenant terminé. <br />\n",
    "Le cluster de machines EMR est **facturé à la demande**, <br />\n",
    "et nous continuons d'être facturé même lorsque <br />\n",
    "les machines sont au repos.<br />\n",
    "Pour **optimiser la facturation**, il nous faut <br />\n",
    "maintenant **résilier le cluster**.\n",
    "\n",
    "<u>Je réalise cette commande depuis l'interface AWS</u> :\n",
    "\n",
    "1. Commencez par **désactiver le tunnel ssh dans FoxyProxy** pour éviter des problèmes de **timeout**.\n",
    "![Désactivation de FoxyProxy](img/EMR_foxyproxy_desactivation.png)\n",
    "2. Cliquez sur \"**Résilier**\"\n",
    "![Cliquez sur Résilier](img/EMR_resiliation_01.png)\n",
    "3. Confirmez la résiliation\n",
    "![Confirmez la résiliation](img/EMR_resiliation_02.png)\n",
    "4. La résiliation prend environ **1 minute**\n",
    "![Résiliation en cours](img/EMR_resiliation_03.png)\n",
    "5. La résiliation est effectuée\n",
    "![Résiliation terminée](img/EMR_resiliation_04.png)\n",
    "\n",
    "## 4.13 Cloner le serveur EMR (si besoin)\n",
    "\n",
    "Si nous devons de nouveau exécuter notre notebook dans les mêmes conditions, <br />\n",
    "il nous suffit de **cloner notre cluster** et ainsi en obtenir une copie fonctionnelle <br />\n",
    "sous 15/20 minutes, le temps de son instanciation.\n",
    "\n",
    "<u>Pour cela deux solutions</u> :\n",
    "1. <u>Depuis l'interface AWS</u> :\n",
    " 1. Cliquez sur \"**Cloner**\"\n",
    "   ![Cloner un cluster](img/EMR_cloner_01.png)\n",
    " 2. Dans notre cas nous ne souhaitons pas inclure d'étapes\n",
    "   ![Ne pas inclure d'étapes](img/EMR_cloner_02.png)\n",
    " 3. La configuration du cluster est recréée à l’identique. <br />\n",
    "    On peut revenir sur les différentes étapes si on souhaite apporter des modifications<br />\n",
    "    Quand tout est prêt, cliquez sur \"**Créer un cluster**\"\n",
    "  ![Vérification/Modification/Créer un cluster](img/EMR_cloner_03.png)\n",
    "2. <u>En ligne de commande</u> (avec AWS CLI d'installé et de configuré et en s'assurant <br />\n",
    "   de s'attribuer les droits nécessaires sur le compte AMI utilisé)\n",
    " 1. Cliquez sur \"**Exporter AWS CLI**\"\n",
    " ![Exporter AWS CLI](img/EMR_cloner_cli_01.png)\n",
    " 2. Copier/Coller la commande **depuis un terminal**\n",
    " ![Copier Coller Commande](img/EMR_cloner_cli_02.png)\n",
    "\n",
    "## 4.14 Arborescence du serveur S3 à la fin du projet\n",
    "\n",
    "<u>Pour information, voici **l'arborescence complète de mon bucket S3 p8-data** à la fin du projet</u> : <br />\n",
    "*Par soucis de lisibilité, je ne liste pas les 131 sous dossiers du répertoire \"Test\"*\n",
    "\n",
    "1. Results/_SUCCESS\n",
    "1. Results/part-00000-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00001-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00002-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00003-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00004-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00005-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00006-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00007-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00008-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00009-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00010-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00011-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00012-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00013-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00014-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00015-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00016-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00017-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00018-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00019-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00020-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00021-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00022-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Results/part-00023-2cc36f38-19ef-4d8a-a0d1-5ddb309b3894-c000.snappy.parquet\n",
    "1. Test/\n",
    "1. bootstrap-emr.sh\n",
    "1. jupyter-s3-conf.json\n",
    "1. jupyter/jovyan/.s3keep\n",
    "1. jupyter/jovyan/P8_01_Notebook.ipynb\n",
    "1. jupyter/jovyan/_metadata\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/file-perm.sqlite\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/html/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbconvert/templates/latex/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/nbsignatures.db\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.aws-editors-workspace-metadata/notebook_secret\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled-checkpoint.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/Untitled1-checkpoint.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/.ipynb_checkpoints/test3-checkpoint.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/Untitled1.ipynb\n",
    "1. jupyter/jovyan/e-5OTY4VKPDT21945FF6DN15E35/test3.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "432.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
